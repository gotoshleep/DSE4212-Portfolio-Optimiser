{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a6f120-5682-4486-9594-a1c2a760f0d6",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "651f515a-b1fa-469d-8d8f-995f2030d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "import cvxpy as cp\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5193d11-e998-426d-a459-c4f776513e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"monthly_log_return_future\"\n",
    "FEATURE_COLS = [\n",
    "    \"volume_log\", \"log_daily_vol_21\", \"log_monthly_var_3\",\n",
    "    \"high_low_spread\", \"open_close_spread\",\n",
    "    \"close_sma_ratio_20\", \"close_ema_ratio_20\",\n",
    "    \"close_sma_ratio_50\", \"close_ema_ratio_50\",\n",
    "    \"close_sma_ratio_100\", \"close_ema_ratio_100\",\n",
    "    \"macd_line_pct\", \"macd_signal_pct\", \"macd_hist_pct\",\n",
    "    \"daily_log_return\", \"daily_volume_return\", \"Dividends\"\n",
    "]\n",
    "RNG = 42\n",
    "N_SPLITS_CV = 5\n",
    "SAVE_DIR = \"linear_ticker_models\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b36171d-4f80-4249-8135-0c4d39c809f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grids for CV Models\n",
    "ALPHA_GRID = np.logspace(-4, 0, 20)      # 20 alpha values from 0.0001 to 1.0\n",
    "L1_RATIOS = [0.1, 0.5, 0.7, 0.9, 0.95, 1.0] # L1 ratios for Elastic Net (1.0 is pure Lasso)\n",
    "\n",
    "TRAIN_WINDOW = 252       # 1 year lookback (trading days) for CV\n",
    "TEST_WINDOW = 21         # 1 month ahead (trading days)\n",
    "PURGE_DAYS = 21          # Days to remove from train to avoid leakage (H)\n",
    "\n",
    "# --- Backtesting Constants ---\n",
    "LOOKBACK = 252           # days for daily μ, Σ estimation\n",
    "HORIZON = 21             # holding period (trading days)\n",
    "STEP = 21                # form a new, independent portfolio every 21 days\n",
    "GAMMA = 5.0              # Markowitz risk aversion parameter\n",
    "NAME_CAP = 0.10          # upper limit for each stock’s weight\n",
    "COST_BPS_ONE_WAY = 5.0   # linear cost per side, in bps of traded notional\n",
    "MIN_NONMISSING_PCT = 0.50 # require >= 50% non-missing in lookback\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ffb39-0fcc-4265-983e-77dcdf571151",
   "metadata": {},
   "source": [
    "###  Markowitz Backtesting Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9dfcfab-02c6-4506-bb3b-ff7dad4827ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ledoit_wolf_cov(rets_values):\n",
    "    \"\"\"Estimates covariance matrix using the Ledoit-Wolf shrinkage method.\"\"\"\n",
    "    lw = LedoitWolf()\n",
    "    lw.fit(rets_values)\n",
    "    # Scale daily covariance up to the 21-day horizon\n",
    "    return lw.covariance_ \n",
    "\n",
    "def ticker_period_compound(rets_df: pd.DataFrame, start_idx: int, horizon: int):\n",
    "    \"\"\"Calculates the simple compound return over the HORIZON for a single leg.\"\"\"\n",
    "    period_returns = rets_df.iloc[start_idx + 1 : start_idx + 1 + horizon]\n",
    "    gross_returns = 1.0 + period_returns\n",
    "    # Missing daily returns are treated as no return (1.0 gross return)\n",
    "    compound_return = gross_returns.fillna(1.0).prod(axis=0) - 1.0\n",
    "    return compound_return\n",
    "\n",
    "def solve_markowitz_long_only(mu_vector, Sigma_matrix, gamma, name_cap=None):\n",
    "    \"\"\"Solves the Markowitz optimization problem using CVXPY.\"\"\"\n",
    "    n = len(mu_vector)\n",
    "    w = cp.Variable(n)\n",
    "    \n",
    "    # Objective: Minimize 0.5 * w'Σw - gamma * μ'w\n",
    "    objective = cp.Minimize(cp.quad_form(w, Sigma_matrix) * 0.5 - gamma * mu_vector @ w)\n",
    "    \n",
    "    constraints = [\n",
    "        cp.sum(w) == 1, \n",
    "        w >= 0          \n",
    "    ]\n",
    "    \n",
    "    if name_cap is not None:\n",
    "        constraints.append(w <= name_cap)\n",
    "        \n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve(solver=cp.ECOS) \n",
    "\n",
    "    if problem.status not in [\"optimal\", \"optimal_inaccurate\"]:\n",
    "        raise RuntimeError(f\"Optimization failed with status: {problem.status}\")\n",
    "        \n",
    "    return w.value\n",
    "\n",
    "def backtest_markowitz_from_mu(rets: pd.DataFrame, is_in_sp500: pd.DataFrame, mu21_hat: pd.DataFrame):\n",
    "    \"\"\"Performs Markowitz backtest using ML-predicted expected returns (mu21_hat).\"\"\"\n",
    "    rets = rets.sort_index().dropna(how=\"all\")\n",
    "    is_in_sp500 = is_in_sp500.reindex_like(rets).fillna(0).astype(int)\n",
    "    mu21_hat = mu21_hat.reindex(index=rets.index, columns=rets.columns)\n",
    "\n",
    "    dates = rets.index\n",
    "    start = LOOKBACK - 1\n",
    "    end = len(dates) - HORIZON - 1\n",
    "    legs = []\n",
    "\n",
    "    for t in range(start, end + 1, STEP):\n",
    "        date_t = dates[t]\n",
    "        \n",
    "        # 1. Universe Selection\n",
    "        tickers = is_in_sp500.columns[is_in_sp500.loc[date_t] == 1].tolist()\n",
    "        if not tickers: continue\n",
    "\n",
    "        # 2. Lookback data for covariance\n",
    "        win = rets.iloc[t-LOOKBACK+1 : t+1][tickers]\n",
    "        \n",
    "        # Quality filter\n",
    "        non_missing_ratio = 1.0 - win.isna().mean()\n",
    "        keep = non_missing_ratio[non_missing_ratio >= MIN_NONMISSING_PCT].index.tolist()\n",
    "        win = win[keep].dropna(how=\"all\").dropna(how=\"any\")\n",
    "        if len(win) < 30 or len(win.columns) < 2: continue\n",
    "        tickers = win.columns.tolist()\n",
    "\n",
    "        # 3. Predicted Returns\n",
    "        mu_row = mu21_hat.loc[date_t, tickers].astype(float).dropna()\n",
    "        if len(mu_row) < 2: continue\n",
    "        \n",
    "        win = win[mu_row.index.tolist()] # Ensure alignment\n",
    "        tickers = mu_row.index.tolist()\n",
    "\n",
    "        # 4. Covariance Estimation\n",
    "        Sigma_d = ledoit_wolf_cov(win.values)\n",
    "        Sigma_21 = HORIZON * Sigma_d\n",
    "        \n",
    "        # 5. Optimization\n",
    "        try:\n",
    "            w = solve_markowitz_long_only(mu_row.values, Sigma_21, gamma=GAMMA, name_cap=NAME_CAP)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "        # 6. Realized Return & Costs\n",
    "        comp_rets = ticker_period_compound(rets[tickers], start_idx=t, horizon=HORIZON)\n",
    "        gross_leg_ret = float(np.dot(w, comp_rets.values))\n",
    "        cost_frac = (COST_BPS_ONE_WAY * 1e-4) * 2.0\n",
    "        net_leg_ret = gross_leg_ret - cost_frac\n",
    "\n",
    "        legs.append({\n",
    "            \"formation_date\": date_t, \"n_names\": len(tickers), \"gross_21d_ret\": gross_leg_ret, \n",
    "            \"net_21d_ret\": net_leg_ret, \"roundtrip_cost_frac\": cost_frac\n",
    "        })\n",
    "\n",
    "    legs_df = pd.DataFrame(legs).set_index(\"formation_date\")\n",
    "\n",
    "    # summary statistics\n",
    "    summary = {}\n",
    "    if not legs_df.empty:\n",
    "        legs_per_year = 252.0 / HORIZON\n",
    "        avg_net = legs_df[\"net_21d_ret\"].mean()\n",
    "        std_net = legs_df[\"net_21d_ret\"].std(ddof=1)\n",
    "        \n",
    "        # Annualized return from compounding the average leg return\n",
    "        ann_return = (1.0 + avg_net)**legs_per_year - 1.0\n",
    "        # Annualized volatility from scaling the leg standard deviation\n",
    "        ann_vol = std_net * np.sqrt(legs_per_year)\n",
    "        \n",
    "        sharpe = ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "        \n",
    "        summary = {\n",
    "            \"legs\": int(len(legs_df)),\n",
    "            \"avg_net_21d_return\": float(avg_net),\n",
    "            \"std_net_21d_return\": float(std_net),\n",
    "            \"annual_return\": float(ann_return), # <--- **CALCULATION ADDED HERE**\n",
    "            \"annual_vol\": float(ann_vol),       # <--- **CALCULATION ADDED HERE**\n",
    "            \"sharpe\": float(sharpe),\n",
    "            \"cost_bps_one_way\": COST_BPS_ONE_WAY,\n",
    "            \"gamma\": GAMMA,\n",
    "            \"name_cap\": NAME_CAP\n",
    "        }\n",
    "    return legs_df, summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed477d7b-6f19-46d9-b819-694194af5373",
   "metadata": {},
   "source": [
    "## Model Training and Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d45e912-b721-4022-aa53-51afa1f01e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_linear_model(model_name: str, model_class, train_df, test_df, covid_test, **model_params):\n",
    "    \"\"\"\n",
    "    Trains a linear model (LassoCV, RidgeCV, ElasticNetCV), makes predictions, \n",
    "    and returns performance metrics and prediction DataFrames.\n",
    "    \n",
    "    This version correctly handles model-specific parameters like 'max_iter', \n",
    "    'n_jobs', and 'random_state'.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Training for {model_name} ---\")\n",
    "    \n",
    "    results_all = []\n",
    "    pred_rows_test = []\n",
    "    pred_rows_covid = []\n",
    "    \n",
    "    # 1. Define model-specific parameters\n",
    "    tscv = TimeSeriesSplit(n_splits=N_SPLITS_CV)\n",
    "    \n",
    "    # Parameters shared by all models (CV object and user-provided params like 'alphas')\n",
    "    base_params = {\n",
    "        \"cv\": tscv, \n",
    "        **model_params\n",
    "    }\n",
    "    \n",
    "    # Iterative solvers (LassoCV and ElasticNetCV) require these\n",
    "    iterative_params = {\n",
    "        \"max_iter\": 2000,\n",
    "        \"n_jobs\": -1,\n",
    "        # random_state is set *after* instantiation due to a bug in some scikit-learn versions\n",
    "        # that affects how it is handled internally for CV models.\n",
    "    }\n",
    "    \n",
    "    # Build the final instantiation parameters\n",
    "    if model_name == \"Ridge\":\n",
    "        # RidgeCV only takes 'cv' and 'alphas' (from **model_params)\n",
    "        final_init_params = base_params\n",
    "    else: # Lasso and ElasticNet\n",
    "        final_init_params = {**base_params, **iterative_params}\n",
    "\n",
    "    \n",
    "    for ticker, df_ticker_train_full in train_df.groupby(\"ticker\"):\n",
    "        \n",
    "        # Prepare Ticker Data\n",
    "        df_ticker_train = df_ticker_train_full.dropna(subset=FEATURE_COLS + [TARGET_COL])\n",
    "        test_ticker = test_df[test_df[\"ticker\"] == ticker].copy().dropna(subset=FEATURE_COLS + [TARGET_COL])\n",
    "        covid_ticker = covid_test[covid_test[\"ticker\"] == ticker].copy().dropna(subset=FEATURE_COLS + [TARGET_COL])\n",
    "\n",
    "        if len(df_ticker_train) < LOOKBACK:\n",
    "            # print(f\"Skipping {ticker} - not enough training data.\")\n",
    "            continue\n",
    "            \n",
    "        # 1. Data Preparation and Scaling\n",
    "        X_train, y_train = df_ticker_train[FEATURE_COLS], df_ticker_train[TARGET_COL]\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "        # 2. Model Training (CV handles alpha selection over TimeSeriesSplit)\n",
    "        \n",
    "        # Instantiate the model with correct parameters\n",
    "        model = model_class(**final_init_params)\n",
    "        \n",
    "        # Set random_state conditionally for iterative solvers (Lasso/ElasticNet)\n",
    "        if model_name in [\"Lasso\", \"ElasticNet\"]:\n",
    "            model.set_params(random_state=RNG)\n",
    "            \n",
    "        try:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "        except Exception as e:\n",
    "            # print(f\"Error fitting {model_name} for {ticker}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        # 3. Save Model and Scaler\n",
    "        save_path = os.path.join(SAVE_DIR, f\"{ticker}_{model_name.lower()}.joblib\")\n",
    "        # Check if the model has alpha_ attribute (it should for all CV models)\n",
    "        best_alpha = getattr(model, 'alpha_', np.nan)\n",
    "        dump({\"model\": model, \"scaler\": scaler, \"best_alpha\": best_alpha}, save_path)\n",
    "        # print(f\"Trained {model_name} for {ticker}. Best alpha: {model.alpha_:.6f}\")\n",
    "\n",
    "\n",
    "        # 4. Predict on Internal Test\n",
    "        if not test_ticker.empty:\n",
    "            X_test_scaled = scaler.transform(test_ticker[FEATURE_COLS])\n",
    "            y_test = test_ticker[TARGET_COL]\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            results_all.append({\"ticker\": ticker, \"split\": \"internal_test\", \"model\": model_name, \"r2\": r2, \"rmse\": rmse})\n",
    "\n",
    "            pred_rows_test.append(pd.DataFrame({\n",
    "                \"Date\": test_ticker[\"Date\"].values, \"ticker\": test_ticker[\"ticker\"].values,\n",
    "                \"y_pred_log\": y_pred, \"y_true_log\": y_test.values\n",
    "            }))\n",
    "\n",
    "        # 5. Predict on COVID Stress Test\n",
    "        if not covid_ticker.empty:\n",
    "            X_covid_scaled = scaler.transform(covid_ticker[FEATURE_COLS])\n",
    "            y_covid = covid_ticker[TARGET_COL]\n",
    "            y_pred_covid = model.predict(X_covid_scaled)\n",
    "            \n",
    "            r2_covid = r2_score(y_covid, y_pred_covid)\n",
    "            rmse_covid = np.sqrt(mean_squared_error(y_covid, y_pred_covid))\n",
    "            results_all.append({\"ticker\": ticker, \"split\": \"covid_stress\", \"model\": model_name, \"r2\": r2_covid, \"rmse\": rmse_covid})\n",
    "\n",
    "            pred_rows_covid.append(pd.DataFrame({\n",
    "                \"Date\": covid_ticker[\"Date\"].values, \"ticker\": covid_ticker[\"ticker\"].values,\n",
    "                \"y_pred_log\": y_pred_covid, \"y_true_log\": y_covid.values\n",
    "            }))\n",
    "\n",
    "    # Compile Results and Predictions\n",
    "    preds_test = pd.concat(pred_rows_test, ignore_index=True) if pred_rows_test else pd.DataFrame()\n",
    "    preds_covid = pd.concat(pred_rows_covid, ignore_index=True) if pred_rows_covid else pd.DataFrame()\n",
    "\n",
    "    if not preds_test.empty:\n",
    "        preds_test[\"R21_pred\"] = np.expm1(preds_test[\"y_pred_log\"])\n",
    "    if not preds_covid.empty:\n",
    "        preds_covid[\"R21_pred\"] = np.expm1(preds_covid[\"y_pred_log\"])\n",
    "\n",
    "    return pd.DataFrame(results_all), preds_test, preds_covid\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10813e-f9fd-4887-a29e-5627bc674d25",
   "metadata": {},
   "source": [
    "## Main Execution Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfca6f5-d048-4b30-91e1-a752366863e5",
   "metadata": {},
   "source": [
    "### Data Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb44845-158a-4b8c-a761-6595dc7bacec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: Training up to 2018-02-16.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_full = pd.read_csv(\"../Data prep and EDA/processed_data/training_data.csv\", parse_dates=[\"Date\"])\n",
    "    covid_test = pd.read_csv(\"../Data prep and EDA/processed_data/covid_stress_test_data.csv\", parse_dates=[\"Date\"])\n",
    "except FileNotFoundError:\n",
    "    print(\"WARNING: Data files not found at expected relative paths. Using local stubs for demonstration.\")\n",
    "    train_full = pd.DataFrame(columns=[\"ticker\", \"Date\", TARGET_COL] + FEATURE_COLS)\n",
    "    covid_test = pd.DataFrame(columns=[\"ticker\", \"Date\", TARGET_COL] + FEATURE_COLS)\n",
    "\n",
    "train_full = train_full.sort_values([\"ticker\", \"Date\"]).reset_index(drop=True)\n",
    "covid_test = covid_test.sort_values([\"ticker\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "# Clean 'Dividends' column if necessary\n",
    "for df in [train_full, covid_test]:\n",
    "    if \"Dividends\" in df.columns:\n",
    "        df[\"Dividends\"] = pd.to_numeric(\n",
    "            df[\"Dividends\"].astype(str).str.replace(\"USD\", \"\", regex=False).str.strip().replace(\"\", np.nan),\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "# Define internal train/test split (last 2 years of the training data)\n",
    "unique_dates = sorted(train_full[\"Date\"].unique())\n",
    "if len(unique_dates) > LOOKBACK * 2:\n",
    "    split_idx = len(unique_dates) - LOOKBACK * 2\n",
    "    split_date = unique_dates[split_idx]\n",
    "    train_df = train_full[train_full[\"Date\"] <= split_date].copy()\n",
    "    test_df = train_full[train_full[\"Date\"] > split_date].copy()\n",
    "    \n",
    "    # Purge last 21 feature dates from train, ticker-wise\n",
    "    H = HORIZON\n",
    "    last_train_by_ticker = train_df.groupby(\"ticker\")[\"Date\"].max().rename(\"last_train_date\")\n",
    "    train_df = train_df.merge(last_train_by_ticker, on=\"ticker\")\n",
    "    train_df = train_df[train_df[\"Date\"] <= (train_df[\"last_train_date\"] - pd.tseries.offsets.BDay(H))]\n",
    "    train_df = train_df.drop(columns=[\"last_train_date\"])\n",
    "\n",
    "    print(f\"Data split: Training up to {split_date.date()}.\")\n",
    "else:\n",
    "    # Use full original training data as train_df, and an empty test_df if data is insufficient\n",
    "    train_df = train_full.copy()\n",
    "    test_df = pd.DataFrame()\n",
    "    print(\"Warning: Insufficient data for a 2-year internal test split.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301d93f-e013-4d5e-86fc-912aa8809698",
   "metadata": {},
   "source": [
    "### Run All Models and Collect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdb551e0-4c26-4b48-b3c9-edc3bee1c861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training for Lasso ---\n",
      "\n",
      "--- Starting Training for Ridge ---\n",
      "\n",
      "--- Starting Training for ElasticNet ---\n"
     ]
    }
   ],
   "source": [
    "model_results = {}\n",
    "backtest_data = {}\n",
    "\n",
    "# 1. Lasso Model\n",
    "results_lasso, preds_test_lasso, preds_covid_lasso = train_and_predict_linear_model(\n",
    "    \"Lasso\", LassoCV, train_df, test_df, covid_test, alphas=ALPHA_GRID.tolist()\n",
    ")\n",
    "model_results[\"Lasso\"] = results_lasso\n",
    "backtest_data[\"Lasso\"] = {\"test\": preds_test_lasso, \"covid\": preds_covid_lasso}\n",
    "\n",
    "# 2. Ridge Model\n",
    "# RidgeCV only needs 'alphas' (passed via **model_params)\n",
    "results_ridge, preds_test_ridge, preds_covid_ridge = train_and_predict_linear_model(\n",
    "    \"Ridge\", RidgeCV, train_df, test_df, covid_test, alphas=ALPHA_GRID.tolist()\n",
    ")\n",
    "model_results[\"Ridge\"] = results_ridge\n",
    "backtest_data[\"Ridge\"] = {\"test\": preds_test_ridge, \"covid\": preds_covid_ridge}\n",
    "\n",
    "\n",
    "# 3. Elastic Net Model\n",
    "results_en, preds_test_en, preds_covid_en = train_and_predict_linear_model(\n",
    "    \"ElasticNet\", ElasticNetCV, train_df, test_df, covid_test, \n",
    "    alphas=ALPHA_GRID.tolist(), l1_ratio=L1_RATIOS\n",
    ")\n",
    "model_results[\"ElasticNet\"] = results_en\n",
    "backtest_data[\"ElasticNet\"] = {\"test\": preds_test_en, \"covid\": preds_covid_en}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e3fce-7c59-40fa-84b9-6a36f544a2b7",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "51d9af6f-7b9e-451c-809e-cb4413f1f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([train_full, covid_test], ignore_index=True)\n",
    "df_full[\"daily_simple_return\"] = np.expm1(df_full[\"daily_log_return\"])\n",
    "rets = df_full.pivot(index=\"Date\", columns=\"ticker\", values=\"daily_simple_return\").sort_index()\n",
    "is_in = df_full.pivot(index=\"Date\", columns=\"ticker\", values=\"is_in_sp500\").sort_index()\n",
    "is_in = is_in.fillna(0).astype(float).clip(0, 1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a294ef22-3fce-4960-80e2-51b0204e8c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "AVERAGE MODEL PREDICTION PERFORMANCE (R2)\n",
      "==================================================\n",
      "split       covid_stress  internal_test\n",
      "model                                  \n",
      "ElasticNet     -0.042915      -0.085392\n",
      "Lasso          -0.043203      -0.085192\n",
      "Ridge          -0.171263      -3.636004\n",
      "\n",
      "==================================================\n",
      "MARKOWITZ BACKTEST RESULTS (All Metrics)\n",
      "==================================================\n",
      "                       Ann. Return  Ann. Volatility  Sharpe Ratio  \\\n",
      "Model      Test Split                                               \n",
      "Lasso      Internal       0.053337         0.302269      0.176455   \n",
      "           COVID          0.740931         0.483255      1.533209   \n",
      "Ridge      Internal       0.227207         0.260368      0.872641   \n",
      "           COVID          0.833616         0.778420      1.070907   \n",
      "ElasticNet Internal       0.037898         0.299824      0.126401   \n",
      "           COVID          0.687046         0.451580      1.521426   \n",
      "\n",
      "                       Avg Net 21d Ret  Legs  \n",
      "Model      Test Split                         \n",
      "Lasso      Internal           0.004340    19  \n",
      "           COVID              0.047286     9  \n",
      "Ridge      Internal           0.017208    19  \n",
      "           COVID              0.051822     9  \n",
      "ElasticNet Internal           0.003105    19  \n",
      "           COVID              0.044545     9  \n",
      "\n",
      "All linear models trained and backtested.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"AVERAGE MODEL PREDICTION PERFORMANCE (R2)\")\n",
    "print(\"=\"*50)\n",
    "summary_r2 = pd.concat(model_results.values()).groupby([\"model\", \"split\"])[\"r2\"].mean().unstack()\n",
    "print(summary_r2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MARKOWITZ BACKTEST RESULTS)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Initialize a list to hold all results dictionaries\n",
    "all_backtest_results = [] \n",
    "\n",
    "for model_name, preds in backtest_data.items():\n",
    "    \n",
    "    # 1. Internal Test Backtest\n",
    "    mu21_hat_internal = preds[\"test\"].pivot(index=\"Date\", columns=\"ticker\", values=\"R21_pred\").sort_index()\n",
    "    if not mu21_hat_internal.empty:\n",
    "        ml_start = mu21_hat_internal.index.min()\n",
    "        \n",
    "        # Define the daily return window required for lookback and holding period\n",
    "        rets_ml = rets.loc[rets.index >= (ml_start - pd.tseries.offsets.BDay(LOOKBACK + HORIZON))]\n",
    "        is_in_ml = is_in.loc[is_in.index >= (ml_start - pd.tseries.offsets.BDay(LOOKBACK + HORIZON))]\n",
    "        \n",
    "        _, summary_ml = backtest_markowitz_from_mu(rets_ml, is_in_ml, mu21_hat_internal)\n",
    "        summary_ml['Model'] = model_name\n",
    "        summary_ml['Test Split'] = 'Internal'\n",
    "        all_backtest_results.append(summary_ml) \n",
    "    else:\n",
    "        all_backtest_results.append({'Model': model_name, 'Test Split': 'Internal', 'sharpe': np.nan, 'annual_return': np.nan, 'annual_vol': np.nan, 'avg_net_21d_return': np.nan})\n",
    "\n",
    "\n",
    "    # 2. COVID Stress Test Backtest\n",
    "    mu21_hat_covid = preds[\"covid\"].pivot(index=\"Date\", columns=\"ticker\", values=\"R21_pred\").sort_index()\n",
    "    if not mu21_hat_covid.empty:\n",
    "        # Use full daily data and S&P 500 membership (rets and is_in)\n",
    "        _, summary_covid = backtest_markowitz_from_mu(rets, is_in, mu21_hat_covid)\n",
    "        summary_covid['Model'] = model_name\n",
    "        summary_covid['Test Split'] = 'COVID'\n",
    "        all_backtest_results.append(summary_covid)\n",
    "    else:\n",
    "        all_backtest_results.append({'Model': model_name, 'Test Split': 'COVID', 'sharpe': np.nan, 'annual_return': np.nan, 'annual_vol': np.nan, 'avg_net_21d_return': np.nan})\n",
    "\n",
    "backtest_results_df = pd.DataFrame(all_backtest_results)\n",
    "backtest_results_df = backtest_results_df.set_index(['Model', 'Test Split'])[\n",
    "    ['annual_return', 'annual_vol', 'sharpe', 'avg_net_21d_return', 'legs']\n",
    "].rename(columns={\n",
    "    'annual_return': 'Ann. Return',\n",
    "    'annual_vol': 'Ann. Volatility',\n",
    "    'sharpe': 'Sharpe Ratio',\n",
    "    'avg_net_21d_return': 'Avg Net 21d Ret',\n",
    "    'legs': 'Legs'\n",
    "})\n",
    "\n",
    "print(backtest_results_df)\n",
    "\n",
    "print(\"\\nAll linear models trained and backtested.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61289b45-b41f-4b83-acfe-fb098db078bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
