{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d98607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b27b793",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw_data/sp_500_historical_components.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m spy_stocklist = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mraw_data/sp_500_historical_components.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Y4S1/DSE4212/project/DSE4212-Portfolio-Optimiser/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Y4S1/DSE4212/project/DSE4212-Portfolio-Optimiser/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Y4S1/DSE4212/project/DSE4212-Portfolio-Optimiser/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Y4S1/DSE4212/project/DSE4212-Portfolio-Optimiser/.venv/lib/python3.14/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/Y4S1/DSE4212/project/DSE4212-Portfolio-Optimiser/.venv/lib/python3.14/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'raw_data/sp_500_historical_components.csv'"
     ]
    }
   ],
   "source": [
    "spy_stocklist = pd.read_csv('raw_data/sp_500_historical_components.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b29a8",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "In this portion of the code we will \n",
    "1) Get the list of stocks that ever existed from sp_500_historical_components.csv from https://github.com/hanshof/sp500_constituents/blob/main/sp_500_historical_components.csv\n",
    "2) Use yfinance library to get historical data (2012-2020) OHLCV, PE ratio, PB ratio from the lists of stocks, indicate their presence in the stock data at any point of time on a daily level. we get 2012 data for a buffer to calculate moving averages later on\n",
    "3) Filter out stocks that newly entered the stock market before 2016, this is to ensure that we have sufficient training data for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67977db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tickers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996-01-02</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996-01-03</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996-01-04</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996-01-10</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996-01-11</td>\n",
       "      <td>AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>2025-08-21</td>\n",
       "      <td>A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3481</th>\n",
       "      <td>2025-08-23</td>\n",
       "      <td>A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date                                            tickers\n",
       "0    1996-01-02  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...\n",
       "1    1996-01-03  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...\n",
       "2    1996-01-04  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...\n",
       "3    1996-01-10  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...\n",
       "4    1996-01-11  AAL,AAMRQ,AAPL,ABI,ABS,ABT,ABX,ACKH,ACV,ADM,AD...\n",
       "...         ...                                                ...\n",
       "3477 2025-08-19  A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...\n",
       "3478 2025-08-20  A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...\n",
       "3479 2025-08-21  A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...\n",
       "3480 2025-08-22  A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...\n",
       "3481 2025-08-23  A,AAPL,ABBV,ABNB,ABT,ACGL,ACN,ADBE,ADI,ADM,ADP...\n",
       "\n",
       "[3482 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convert 'date' column to datetime\n",
    "spy_stocklist['date'] = pd.to_datetime(spy_stocklist['date'])\n",
    "\n",
    "# Ensure 'tickers' is string\n",
    "spy_stocklist['tickers'] = spy_stocklist['tickers'].astype(str)\n",
    "spy_stocklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter date range for 2012-01-01 to 2021-01-07, we include the year 2012 to introduce a buffer for moving averages calculation\n",
    "spy_stocklist_filtered = spy_stocklist[(spy_stocklist['date'] >= '2013-01-01') & (spy_stocklist['date'] <= '2020-12-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55986e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>ABT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343971</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>YUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343972</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>ZBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343973</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>ZBRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343974</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>ZION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343975</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343976 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date ticker\n",
       "0      2013-01-02      A\n",
       "1      2013-01-02   AAPL\n",
       "2      2013-01-02   ABBV\n",
       "3      2013-01-02    ABC\n",
       "4      2013-01-02    ABT\n",
       "...           ...    ...\n",
       "343971 2020-12-21    YUM\n",
       "343972 2020-12-21    ZBH\n",
       "343973 2020-12-21   ZBRA\n",
       "343974 2020-12-21   ZION\n",
       "343975 2020-12-21    ZTS\n",
       "\n",
       "[343976 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_stocklist_filtered_expanded = (\n",
    "    spy_stocklist_filtered.assign(ticker=spy_stocklist_filtered[\"tickers\"].str.split(\",\"))\n",
    "      .explode(\"ticker\")\n",
    "      .drop(columns=\"tickers\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "spy_stocklist_filtered_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc75e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are certain cases where a stock may have rebranded, we will update the list accordingly later\n",
    "## TODO\n",
    "updated_ticker_mapping = {\n",
    "    'GOOGL': 'GOOG',  \n",
    "    'FB': 'META',     \n",
    "    'TWTR': 'X',      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3912ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining a function to replace the tickers\n",
    "\n",
    "def update_tickers_in_df_from_dict(df, column, ticker_map):\n",
    "\n",
    "    df_updated = df.copy()\n",
    "\n",
    "    # Replace using pandas built-in mapping\n",
    "    df_updated[column] = df_updated[column].replace(ticker_map)\n",
    "\n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343416</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343649</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343674</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343675</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343917</th>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date ticker\n",
       "185    2013-01-02   GOOG\n",
       "448    2013-01-02      X\n",
       "643    2013-01-03   GOOG\n",
       "906    2013-01-03      X\n",
       "1101   2013-01-08   GOOG\n",
       "...           ...    ...\n",
       "343416 2020-11-17      X\n",
       "343649 2020-12-21   META\n",
       "343674 2020-12-21   GOOG\n",
       "343675 2020-12-21   GOOG\n",
       "343917 2020-12-21      X\n",
       "\n",
       "[2194 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy_stocklist_final = update_tickers_in_df_from_dict(spy_stocklist_filtered_expanded, \"ticker\", updated_ticker_mapping)\n",
    "spy_stocklist_final[spy_stocklist_final['ticker'].isin(updated_ticker_mapping.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521f674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tickers in S&P 500 from 2013 to 2020: 639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'AAPL',\n",
       " 'ABBV',\n",
       " 'ABC',\n",
       " 'ABT',\n",
       " 'ACN',\n",
       " 'ADBE',\n",
       " 'ADI',\n",
       " 'ADM',\n",
       " 'ADP',\n",
       " 'ADSK',\n",
       " 'AEE',\n",
       " 'AEP',\n",
       " 'AES',\n",
       " 'AET',\n",
       " 'AFL',\n",
       " 'AIG',\n",
       " 'AIV',\n",
       " 'AIZ',\n",
       " 'AKAM',\n",
       " 'ALL',\n",
       " 'ALXN',\n",
       " 'AMAT',\n",
       " 'AMD',\n",
       " 'AMGN',\n",
       " 'AMP',\n",
       " 'AMT',\n",
       " 'AMZN',\n",
       " 'AN',\n",
       " 'ANDV',\n",
       " 'ANF',\n",
       " 'ANTM',\n",
       " 'AON',\n",
       " 'APA',\n",
       " 'APC',\n",
       " 'APD',\n",
       " 'APH',\n",
       " 'APOL',\n",
       " 'APTV',\n",
       " 'ARG',\n",
       " 'ATI',\n",
       " 'AVB',\n",
       " 'AVP',\n",
       " 'AVY',\n",
       " 'AXP',\n",
       " 'AZO',\n",
       " 'BA',\n",
       " 'BAC',\n",
       " 'BAX',\n",
       " 'BBBY',\n",
       " 'BBT',\n",
       " 'BBY',\n",
       " 'BCR',\n",
       " 'BDX',\n",
       " 'BEN',\n",
       " 'BF-B',\n",
       " 'BIG',\n",
       " 'BIIB',\n",
       " 'BK',\n",
       " 'BKNG',\n",
       " 'BLK',\n",
       " 'BLL',\n",
       " 'BMS',\n",
       " 'BMY',\n",
       " 'BRCM',\n",
       " 'BRK-B',\n",
       " 'BSX',\n",
       " 'BTUUQ',\n",
       " 'BWA',\n",
       " 'BXP',\n",
       " 'C',\n",
       " 'CA',\n",
       " 'CAG',\n",
       " 'CAH',\n",
       " 'CAM',\n",
       " 'CAT',\n",
       " 'CB',\n",
       " 'CBRE',\n",
       " 'CBS',\n",
       " 'CCI',\n",
       " 'CCL',\n",
       " 'CELG',\n",
       " 'CERN',\n",
       " 'CF',\n",
       " 'CFN',\n",
       " 'CHRW',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CL',\n",
       " 'CLF',\n",
       " 'CLX',\n",
       " 'CMA',\n",
       " 'CMCSA',\n",
       " 'CME',\n",
       " 'CMG',\n",
       " 'CMI',\n",
       " 'CMS',\n",
       " 'CNP',\n",
       " 'CNX',\n",
       " 'COF',\n",
       " 'COG',\n",
       " 'COL',\n",
       " 'COP',\n",
       " 'COST',\n",
       " 'COV',\n",
       " 'CPB',\n",
       " 'CRM',\n",
       " 'CSCO',\n",
       " 'CSX',\n",
       " 'CTAS',\n",
       " 'CTL',\n",
       " 'CTSH',\n",
       " 'CTXS',\n",
       " 'CVC',\n",
       " 'CVS',\n",
       " 'CVX',\n",
       " 'D',\n",
       " 'DD',\n",
       " 'DE',\n",
       " 'DF',\n",
       " 'DFS',\n",
       " 'DG',\n",
       " 'DGX',\n",
       " 'DHI',\n",
       " 'DHR',\n",
       " 'DIS',\n",
       " 'DISCA',\n",
       " 'DLTR',\n",
       " 'DNR',\n",
       " 'DOV',\n",
       " 'DRI',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DVA',\n",
       " 'DVN',\n",
       " 'DXC',\n",
       " 'EA',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'ED',\n",
       " 'EFX',\n",
       " 'EIX',\n",
       " 'EL',\n",
       " 'EMN',\n",
       " 'EMR',\n",
       " 'EOG',\n",
       " 'EQR',\n",
       " 'EQT',\n",
       " 'ES',\n",
       " 'ESRX',\n",
       " 'ESV',\n",
       " 'ETFC',\n",
       " 'ETN',\n",
       " 'ETR',\n",
       " 'EW',\n",
       " 'EXC',\n",
       " 'EXPD',\n",
       " 'EXPE',\n",
       " 'F',\n",
       " 'FAST',\n",
       " 'FCX',\n",
       " 'FDO',\n",
       " 'FDX',\n",
       " 'FE',\n",
       " 'FFIV',\n",
       " 'FHN',\n",
       " 'FIS',\n",
       " 'FISV',\n",
       " 'FITB',\n",
       " 'FLIR',\n",
       " 'FLR',\n",
       " 'FLS',\n",
       " 'FMC',\n",
       " 'FRX',\n",
       " 'FSLR',\n",
       " 'FTI',\n",
       " 'FTR',\n",
       " 'GD',\n",
       " 'GE',\n",
       " 'GHC',\n",
       " 'GILD',\n",
       " 'GIS',\n",
       " 'GLW',\n",
       " 'GME',\n",
       " 'GNW',\n",
       " 'GOOG',\n",
       " 'GPC',\n",
       " 'GPS',\n",
       " 'GRMN',\n",
       " 'GS',\n",
       " 'GT',\n",
       " 'GWW',\n",
       " 'HAL',\n",
       " 'HAS',\n",
       " 'HBAN',\n",
       " 'HCBK',\n",
       " 'HD',\n",
       " 'HES',\n",
       " 'HIG',\n",
       " 'HNZ',\n",
       " 'HOG',\n",
       " 'HON',\n",
       " 'HP',\n",
       " 'HPQ',\n",
       " 'HRB',\n",
       " 'HRL',\n",
       " 'HRS',\n",
       " 'HSP',\n",
       " 'HST',\n",
       " 'HSY',\n",
       " 'HUM',\n",
       " 'IBM',\n",
       " 'ICE',\n",
       " 'IFF',\n",
       " 'IGT',\n",
       " 'INTC',\n",
       " 'INTU',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'IRM',\n",
       " 'ISRG',\n",
       " 'ITW',\n",
       " 'IVZ',\n",
       " 'JBL',\n",
       " 'JCI',\n",
       " 'JCP',\n",
       " 'JEC',\n",
       " 'JEF',\n",
       " 'JNJ',\n",
       " 'JNPR',\n",
       " 'JOY',\n",
       " 'JPM',\n",
       " 'JWN',\n",
       " 'K',\n",
       " 'KDP',\n",
       " 'KEY',\n",
       " 'KIM',\n",
       " 'KLAC',\n",
       " 'KMB',\n",
       " 'KMI',\n",
       " 'KMX',\n",
       " 'KO',\n",
       " 'KR',\n",
       " 'KRFT',\n",
       " 'KSS',\n",
       " 'L',\n",
       " 'LB',\n",
       " 'LDOS',\n",
       " 'LEG',\n",
       " 'LEN',\n",
       " 'LH',\n",
       " 'LLTC',\n",
       " 'LLY',\n",
       " 'LM',\n",
       " 'LMT',\n",
       " 'LNC',\n",
       " 'LO',\n",
       " 'LOW',\n",
       " 'LRCX',\n",
       " 'LSI',\n",
       " 'LUV',\n",
       " 'LYB',\n",
       " 'M',\n",
       " 'MA',\n",
       " 'MAR',\n",
       " 'MAS',\n",
       " 'MAT',\n",
       " 'MCD',\n",
       " 'MCHP',\n",
       " 'MCK',\n",
       " 'MCO',\n",
       " 'MDLZ',\n",
       " 'MDT',\n",
       " 'MET',\n",
       " 'MJN',\n",
       " 'MKC',\n",
       " 'MMC',\n",
       " 'MMM',\n",
       " 'MNST',\n",
       " 'MO',\n",
       " 'MOLX',\n",
       " 'MOS',\n",
       " 'MPC',\n",
       " 'MRK',\n",
       " 'MRO',\n",
       " 'MS',\n",
       " 'MSFT',\n",
       " 'MSI',\n",
       " 'MTB',\n",
       " 'MU',\n",
       " 'MUR',\n",
       " 'MWV',\n",
       " 'MYL',\n",
       " 'NBL',\n",
       " 'NBR',\n",
       " 'NDAQ',\n",
       " 'NEE',\n",
       " 'NEM',\n",
       " 'NFLX',\n",
       " 'NFX',\n",
       " 'NI',\n",
       " 'NKE',\n",
       " 'NOC',\n",
       " 'NOV',\n",
       " 'NRG',\n",
       " 'NSC',\n",
       " 'NTAP',\n",
       " 'NTRS',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NWL',\n",
       " 'NYX',\n",
       " 'OI',\n",
       " 'OKE',\n",
       " 'OMC',\n",
       " 'ORCL',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'PAYX',\n",
       " 'PBCT',\n",
       " 'PBI',\n",
       " 'PCAR',\n",
       " 'PCG',\n",
       " 'PDCO',\n",
       " 'PEG',\n",
       " 'PEP',\n",
       " 'PETM',\n",
       " 'PFE',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PH',\n",
       " 'PHM',\n",
       " 'PKI',\n",
       " 'PLD',\n",
       " 'PM',\n",
       " 'PNC',\n",
       " 'PNR',\n",
       " 'PNW',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PRGO',\n",
       " 'PRU',\n",
       " 'PSA',\n",
       " 'PSX',\n",
       " 'PWR',\n",
       " 'PXD',\n",
       " 'QCOM',\n",
       " 'QEP',\n",
       " 'R',\n",
       " 'RAI',\n",
       " 'RDC',\n",
       " 'RF',\n",
       " 'RHI',\n",
       " 'RHT',\n",
       " 'RL',\n",
       " 'ROK',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RRC',\n",
       " 'RSG',\n",
       " 'RTN',\n",
       " 'SBUX',\n",
       " 'SCG',\n",
       " 'SCHW',\n",
       " 'SEE',\n",
       " 'SHW',\n",
       " 'SIAL',\n",
       " 'SJM',\n",
       " 'SLB',\n",
       " 'SLM',\n",
       " 'SNA',\n",
       " 'SNDK',\n",
       " 'SNI',\n",
       " 'SO',\n",
       " 'SPG',\n",
       " 'SPGI',\n",
       " 'SPLS',\n",
       " 'SRCL',\n",
       " 'SRE',\n",
       " 'STI',\n",
       " 'STJ',\n",
       " 'STT',\n",
       " 'STX',\n",
       " 'STZ',\n",
       " 'SWK',\n",
       " 'SWN',\n",
       " 'SWY',\n",
       " 'SYK',\n",
       " 'SYMC',\n",
       " 'SYY',\n",
       " 'T',\n",
       " 'TAP',\n",
       " 'TDC',\n",
       " 'TE',\n",
       " 'TEL',\n",
       " 'TER',\n",
       " 'TGNA',\n",
       " 'TGT',\n",
       " 'THC',\n",
       " 'TIF',\n",
       " 'TJX',\n",
       " 'TMK',\n",
       " 'TMO',\n",
       " 'TMUS',\n",
       " 'TPR',\n",
       " 'TRIP',\n",
       " 'TROW',\n",
       " 'TRV',\n",
       " 'TSN',\n",
       " 'TSS',\n",
       " 'TWC',\n",
       " 'TWX',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'UNH',\n",
       " 'UNM',\n",
       " 'UNP',\n",
       " 'UPS',\n",
       " 'USB',\n",
       " 'UTX',\n",
       " 'V',\n",
       " 'VAR',\n",
       " 'VFC',\n",
       " 'VIAB',\n",
       " 'VIAV',\n",
       " 'VLO',\n",
       " 'VMC',\n",
       " 'VNO',\n",
       " 'VRSN',\n",
       " 'VTR',\n",
       " 'VZ',\n",
       " 'WAT',\n",
       " 'WBA',\n",
       " 'WDC',\n",
       " 'WEC',\n",
       " 'WELL',\n",
       " 'WFC',\n",
       " 'WFM',\n",
       " 'WHR',\n",
       " 'WIN',\n",
       " 'WM',\n",
       " 'WMB',\n",
       " 'WMT',\n",
       " 'WPX',\n",
       " 'WU',\n",
       " 'WY',\n",
       " 'WYNN',\n",
       " 'X',\n",
       " 'XEL',\n",
       " 'XLNX',\n",
       " 'XOM',\n",
       " 'XRAY',\n",
       " 'XRX',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBH',\n",
       " 'ZION',\n",
       " 'PVH',\n",
       " 'REGN',\n",
       " 'MAC',\n",
       " 'KSU',\n",
       " 'GM',\n",
       " 'ZTS',\n",
       " 'NWSA',\n",
       " 'NLSN',\n",
       " 'DAL',\n",
       " 'AME',\n",
       " 'VRTX',\n",
       " 'KORS',\n",
       " 'ALLE',\n",
       " 'GGP',\n",
       " 'ADS',\n",
       " 'META',\n",
       " 'MHK',\n",
       " 'TSCO',\n",
       " 'GMCR',\n",
       " 'ESS',\n",
       " 'NAVI',\n",
       " 'UAA',\n",
       " 'AVGO',\n",
       " 'XEC',\n",
       " 'AMG',\n",
       " 'MLM',\n",
       " 'DISCK',\n",
       " 'UHS',\n",
       " 'URI',\n",
       " 'LVLT',\n",
       " 'RCL',\n",
       " 'ENDP',\n",
       " 'HCA',\n",
       " 'SWKS',\n",
       " 'HSIC',\n",
       " 'AAL',\n",
       " 'EQIX',\n",
       " 'HBI',\n",
       " 'SLG',\n",
       " 'O',\n",
       " 'QRVO',\n",
       " 'BXLT',\n",
       " 'JBHT',\n",
       " 'CPGX',\n",
       " 'WRK',\n",
       " 'KHC',\n",
       " 'AAP',\n",
       " 'PYPL',\n",
       " 'ATVI',\n",
       " 'UAL',\n",
       " 'CMCSK',\n",
       " 'NWS',\n",
       " 'VRSK',\n",
       " 'HPE',\n",
       " 'FCPT',\n",
       " 'SYF',\n",
       " 'ILMN',\n",
       " 'CSRA',\n",
       " 'CHD',\n",
       " 'CPRI',\n",
       " 'WLTW',\n",
       " 'EXR',\n",
       " 'CFG',\n",
       " 'FRT',\n",
       " 'CXO',\n",
       " 'AWK',\n",
       " 'UDR',\n",
       " 'CNC',\n",
       " 'HOLX',\n",
       " 'FL',\n",
       " 'UA',\n",
       " 'ULTA',\n",
       " 'GPN',\n",
       " 'AYI',\n",
       " 'ALK',\n",
       " 'DLR',\n",
       " 'LKQ',\n",
       " 'AJG',\n",
       " 'TDG',\n",
       " 'FBHS',\n",
       " 'ALB',\n",
       " 'LNT',\n",
       " 'FTV',\n",
       " 'MTD',\n",
       " 'CHTR',\n",
       " 'COO',\n",
       " 'COTY',\n",
       " 'EVHC',\n",
       " 'MAA',\n",
       " 'IDXX',\n",
       " 'INCY',\n",
       " 'CBOE',\n",
       " 'REG',\n",
       " 'DISH',\n",
       " 'SNPS',\n",
       " 'ARE',\n",
       " 'RJF',\n",
       " 'IT',\n",
       " 'INFO',\n",
       " 'ALGN',\n",
       " 'ANSS',\n",
       " 'HLT',\n",
       " 'RE',\n",
       " 'AOS',\n",
       " 'DRE',\n",
       " 'MGM',\n",
       " 'PKG',\n",
       " 'RMD',\n",
       " 'BHF',\n",
       " 'IQV',\n",
       " 'DWDP',\n",
       " 'SBAC',\n",
       " 'CDNS',\n",
       " 'NCLH',\n",
       " 'HII',\n",
       " 'IPGP',\n",
       " 'NKTR',\n",
       " 'SIVB',\n",
       " 'TTWO',\n",
       " 'MSCI',\n",
       " 'ABMD',\n",
       " 'EVRG',\n",
       " 'BR',\n",
       " 'HFC',\n",
       " 'FLT',\n",
       " 'CPRT',\n",
       " 'ANET',\n",
       " 'WCG',\n",
       " 'ROL',\n",
       " 'FTNT',\n",
       " 'KEYS',\n",
       " 'LIN',\n",
       " 'JKHY',\n",
       " 'FANG',\n",
       " 'LW',\n",
       " 'MXIM',\n",
       " 'CE',\n",
       " 'FRC',\n",
       " 'TFX',\n",
       " 'ATO',\n",
       " 'WAB',\n",
       " 'LHX',\n",
       " 'CTVA',\n",
       " 'AMCR',\n",
       " 'MKTX',\n",
       " 'GL',\n",
       " 'IEX',\n",
       " 'CDW',\n",
       " 'NVR',\n",
       " 'LVS',\n",
       " 'BKR',\n",
       " 'NLOK',\n",
       " 'PEAK',\n",
       " 'NOW',\n",
       " 'VIAC',\n",
       " 'WRB',\n",
       " 'ODFL',\n",
       " 'TFC',\n",
       " 'J',\n",
       " 'LYV',\n",
       " 'STE',\n",
       " 'ZBRA',\n",
       " 'PAYC',\n",
       " 'TT',\n",
       " 'CARR',\n",
       " 'OTIS',\n",
       " 'RTX',\n",
       " 'HWM',\n",
       " 'DPZ',\n",
       " 'DXCM',\n",
       " 'WST',\n",
       " 'BIO',\n",
       " 'TDY',\n",
       " 'TYL',\n",
       " 'LUMN',\n",
       " 'CTLT',\n",
       " 'ETSY',\n",
       " 'POOL',\n",
       " 'VNT',\n",
       " 'VTRS',\n",
       " 'TSLA']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### getting list of unique tickers that ever entered the SP500 between 2013-2020\n",
    "unique_tickers = spy_stocklist_final['ticker'].unique().tolist()\n",
    "print(f\"Total unique tickers in S&P 500 from 2013 to 2020: {len(unique_tickers)}\")\n",
    "unique_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we will use the yfinance library to get the historical data for these tickers that ever existed in the SP500 between 2013-2020\n",
    "def get_stock_data(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Convert string to datetime so we can safely add 1 day, because yfinance end date is exclusive we add one day to include the end date\n",
    "        end_date_dt = pd.to_datetime(end_date) + pd.Timedelta(days=1)\n",
    "        \n",
    "        stock = yf.Ticker(ticker)\n",
    "        stock_data = stock.history(\n",
    "            start=start_date,\n",
    "            end=end_date_dt,\n",
    "            auto_adjust=True,  # adjust for stock splits/dividends\n",
    "            actions=True       # include Dividends and Stock Splits columns\n",
    "        )\n",
    "        \n",
    "        if stock_data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        stock_data[\"ticker\"] = ticker\n",
    "        return stock_data.reset_index()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d563e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for A...\n",
      "Fetching data for AAPL...\n",
      "Fetching data for ABBV...\n",
      "Fetching data for ABC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ABC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ABT...\n",
      "Fetching data for ACN...\n",
      "Fetching data for ADBE...\n",
      "Fetching data for ADI...\n",
      "Fetching data for ADM...\n",
      "Fetching data for ADP...\n",
      "Fetching data for ADSK...\n",
      "Fetching data for AEE...\n",
      "Fetching data for AEP...\n",
      "Fetching data for AES...\n",
      "Fetching data for AET...\n",
      "Fetching data for AFL...\n",
      "Fetching data for AIG...\n",
      "Fetching data for AIV...\n",
      "Fetching data for AIZ...\n",
      "Fetching data for AKAM...\n",
      "Fetching data for ALL...\n",
      "Fetching data for ALXN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ALXN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AMAT...\n",
      "Fetching data for AMD...\n",
      "Fetching data for AMGN...\n",
      "Fetching data for AMP...\n",
      "Fetching data for AMT...\n",
      "Fetching data for AMZN...\n",
      "Fetching data for AN...\n",
      "Fetching data for ANDV...\n",
      "Fetching data for ANF...\n",
      "Fetching data for ANTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ANTM: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AON...\n",
      "Fetching data for APA...\n",
      "Fetching data for APC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$APC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for APD...\n",
      "Fetching data for APH...\n",
      "Fetching data for APOL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$APOL: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n",
      "$ARG: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for APTV...\n",
      "Fetching data for ARG...\n",
      "Fetching data for ATI...\n",
      "Fetching data for AVB...\n",
      "Fetching data for AVP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AVP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AVY...\n",
      "Fetching data for AXP...\n",
      "Fetching data for AZO...\n",
      "Fetching data for BA...\n",
      "Fetching data for BAC...\n",
      "Fetching data for BAX...\n",
      "Fetching data for BBBY...\n",
      "Fetching data for BBT...\n",
      "Fetching data for BBY...\n",
      "Fetching data for BCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BCR: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BDX...\n",
      "Fetching data for BEN...\n",
      "Fetching data for BF-B...\n",
      "Fetching data for BIG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BIG: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BIIB...\n",
      "Fetching data for BK...\n",
      "Fetching data for BKNG...\n",
      "Fetching data for BLK...\n",
      "Fetching data for BLL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BLL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BMS...\n",
      "Fetching data for BMY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BRCM: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BRCM...\n",
      "Fetching data for BRK-B...\n",
      "Fetching data for BSX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BTUUQ: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BTUUQ...\n",
      "Fetching data for BWA...\n",
      "Fetching data for BXP...\n",
      "Fetching data for C...\n",
      "Fetching data for CA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CA: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00) (Yahoo error = \"Data doesn't exist for startDate = 1325394000, endDate = 1609477200\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CAG...\n",
      "Fetching data for CAH...\n",
      "Fetching data for CAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CAM: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00) (Yahoo error = \"Data doesn't exist for startDate = 1325394000, endDate = 1609477200\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CAT...\n",
      "Fetching data for CB...\n",
      "Fetching data for CBRE...\n",
      "Fetching data for CBS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CBS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CCI...\n",
      "Fetching data for CCL...\n",
      "Fetching data for CELG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CELG: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CERN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CERN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CF...\n",
      "Fetching data for CFN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CFN: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CHRW...\n",
      "Fetching data for CI...\n",
      "Fetching data for CINF...\n",
      "Fetching data for CL...\n",
      "Fetching data for CLF...\n",
      "Fetching data for CLX...\n",
      "Fetching data for CMA...\n",
      "Fetching data for CMCSA...\n",
      "Fetching data for CME...\n",
      "Fetching data for CMG...\n",
      "Fetching data for CMI...\n",
      "Fetching data for CMS...\n",
      "Fetching data for CNP...\n",
      "Fetching data for CNX...\n",
      "Fetching data for COF...\n",
      "Fetching data for COG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$COG: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for COL...\n",
      "Fetching data for COP...\n",
      "Fetching data for COST...\n",
      "Fetching data for COV...\n",
      "Fetching data for CPB...\n",
      "Fetching data for CRM...\n",
      "Fetching data for CSCO...\n",
      "Fetching data for CSX...\n",
      "Fetching data for CTAS...\n",
      "Fetching data for CTL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CTL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CTSH...\n",
      "Fetching data for CTXS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CTXS: possibly delisted; no timezone found\n",
      "$CVC: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CVC...\n",
      "Fetching data for CVS...\n",
      "Fetching data for CVX...\n",
      "Fetching data for D...\n",
      "Fetching data for DD...\n",
      "Fetching data for DE...\n",
      "Fetching data for DF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DF: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DFS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DFS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DG...\n",
      "Fetching data for DGX...\n",
      "Fetching data for DHI...\n",
      "Fetching data for DHR...\n",
      "Fetching data for DIS...\n",
      "Fetching data for DISCA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DISCA: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DLTR...\n",
      "Fetching data for DNR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DNR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DOV...\n",
      "Fetching data for DRI...\n",
      "Fetching data for DTE...\n",
      "Fetching data for DUK...\n",
      "Fetching data for DVA...\n",
      "Fetching data for DVN...\n",
      "Fetching data for DXC...\n",
      "Fetching data for EA...\n",
      "Fetching data for EBAY...\n",
      "Fetching data for ECL...\n",
      "Fetching data for ED...\n",
      "Fetching data for EFX...\n",
      "Fetching data for EIX...\n",
      "Fetching data for EL...\n",
      "Fetching data for EMN...\n",
      "Fetching data for EMR...\n",
      "Fetching data for EOG...\n",
      "Fetching data for EQR...\n",
      "Fetching data for EQT...\n",
      "Fetching data for ES...\n",
      "Fetching data for ESRX...\n",
      "Fetching data for ESV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ESV: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ETFC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ETFC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ETN...\n",
      "Fetching data for ETR...\n",
      "Fetching data for EW...\n",
      "Fetching data for EXC...\n",
      "Fetching data for EXPD...\n",
      "Fetching data for EXPE...\n",
      "Fetching data for F...\n",
      "Fetching data for FAST...\n",
      "Fetching data for FCX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FDO: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for FDO...\n",
      "Fetching data for FDX...\n",
      "Fetching data for FE...\n",
      "Fetching data for FFIV...\n",
      "Fetching data for FHN...\n",
      "Fetching data for FIS...\n",
      "Fetching data for FISV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FISV: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for FITB...\n",
      "Fetching data for FLIR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FLIR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for FLR...\n",
      "Fetching data for FLS...\n",
      "Fetching data for FMC...\n",
      "Fetching data for FRX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FRX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for FSLR...\n",
      "Fetching data for FTI...\n",
      "Fetching data for FTR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FTR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GD...\n",
      "Fetching data for GE...\n",
      "Fetching data for GHC...\n",
      "Fetching data for GILD...\n",
      "Fetching data for GIS...\n",
      "Fetching data for GLW...\n",
      "Fetching data for GME...\n",
      "Fetching data for GNW...\n",
      "Fetching data for GOOG...\n",
      "Fetching data for GPC...\n",
      "Fetching data for GPS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GPS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GRMN...\n",
      "Fetching data for GS...\n",
      "Fetching data for GT...\n",
      "Fetching data for GWW...\n",
      "Fetching data for HAL...\n",
      "Fetching data for HAS...\n",
      "Fetching data for HBAN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HCBK: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HCBK...\n",
      "Fetching data for HD...\n",
      "Fetching data for HES...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HES: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HIG...\n",
      "Fetching data for HNZ...\n",
      "Fetching data for HOG...\n",
      "Fetching data for HON...\n",
      "Fetching data for HP...\n",
      "Fetching data for HPQ...\n",
      "Fetching data for HRB...\n",
      "Fetching data for HRL...\n",
      "Fetching data for HRS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HRS: possibly delisted; no timezone found\n",
      "$HSP: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HSP...\n",
      "Fetching data for HST...\n",
      "Fetching data for HSY...\n",
      "Fetching data for HUM...\n",
      "Fetching data for IBM...\n",
      "Fetching data for ICE...\n",
      "Fetching data for IFF...\n",
      "Fetching data for IGT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$IGT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for INTC...\n",
      "Fetching data for INTU...\n",
      "Fetching data for IP...\n",
      "Fetching data for IPG...\n",
      "Fetching data for IRM...\n",
      "Fetching data for ISRG...\n",
      "Fetching data for ITW...\n",
      "Fetching data for IVZ...\n",
      "Fetching data for JBL...\n",
      "Fetching data for JCI...\n",
      "Fetching data for JCP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JCP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JEC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JEC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JEF...\n",
      "Fetching data for JNJ...\n",
      "Fetching data for JNPR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JNPR: possibly delisted; no timezone found\n",
      "$JOY: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for JOY...\n",
      "Fetching data for JPM...\n",
      "Fetching data for JWN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$JWN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for K...\n",
      "Fetching data for KDP...\n",
      "Fetching data for KEY...\n",
      "Fetching data for KIM...\n",
      "Fetching data for KLAC...\n",
      "Fetching data for KMB...\n",
      "Fetching data for KMI...\n",
      "Fetching data for KMX...\n",
      "Fetching data for KO...\n",
      "Fetching data for KR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KRFT: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for KRFT...\n",
      "Fetching data for KSS...\n",
      "Fetching data for L...\n",
      "Fetching data for LB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LB: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00) (Yahoo error = \"Data doesn't exist for startDate = 1325394000, endDate = 1609477200\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LDOS...\n",
      "Fetching data for LEG...\n",
      "Fetching data for LEN...\n",
      "Fetching data for LH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LLTC: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LLTC...\n",
      "Fetching data for LLY...\n",
      "Fetching data for LM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LM: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LMT...\n",
      "Fetching data for LNC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LO: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LO...\n",
      "Fetching data for LOW...\n",
      "Fetching data for LRCX...\n",
      "Fetching data for LSI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LSI: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for LUV...\n",
      "Fetching data for LYB...\n",
      "Fetching data for M...\n",
      "Fetching data for MA...\n",
      "Fetching data for MAR...\n",
      "Fetching data for MAS...\n",
      "Fetching data for MAT...\n",
      "Fetching data for MCD...\n",
      "Fetching data for MCHP...\n",
      "Fetching data for MCK...\n",
      "Fetching data for MCO...\n",
      "Fetching data for MDLZ...\n",
      "Fetching data for MDT...\n",
      "Fetching data for MET...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MJN: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MJN...\n",
      "Fetching data for MKC...\n",
      "Fetching data for MMC...\n",
      "Fetching data for MMM...\n",
      "Fetching data for MNST...\n",
      "Fetching data for MO...\n",
      "Fetching data for MOLX...\n",
      "Fetching data for MOS...\n",
      "Fetching data for MPC...\n",
      "Fetching data for MRK...\n",
      "Fetching data for MRO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MRO: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MS...\n",
      "Fetching data for MSFT...\n",
      "Fetching data for MSI...\n",
      "Fetching data for MTB...\n",
      "Fetching data for MU...\n",
      "Fetching data for MUR...\n",
      "Fetching data for MWV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MWV: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MYL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MYL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NBL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NBL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NBR...\n",
      "Fetching data for NDAQ...\n",
      "Fetching data for NEE...\n",
      "Fetching data for NEM...\n",
      "Fetching data for NFLX...\n",
      "Fetching data for NFX...\n",
      "Fetching data for NI...\n",
      "Fetching data for NKE...\n",
      "Fetching data for NOC...\n",
      "Fetching data for NOV...\n",
      "Fetching data for NRG...\n",
      "Fetching data for NSC...\n",
      "Fetching data for NTAP...\n",
      "Fetching data for NTRS...\n",
      "Fetching data for NUE...\n",
      "Fetching data for NVDA...\n",
      "Fetching data for NWL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NYX: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NYX...\n",
      "Fetching data for OI...\n",
      "Fetching data for OKE...\n",
      "Fetching data for OMC...\n",
      "Fetching data for ORCL...\n",
      "Fetching data for ORLY...\n",
      "Fetching data for OXY...\n",
      "Fetching data for PAYX...\n",
      "Fetching data for PBCT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PBCT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PBI...\n",
      "Fetching data for PCAR...\n",
      "Fetching data for PCG...\n",
      "Fetching data for PDCO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PDCO: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PEG...\n",
      "Fetching data for PEP...\n",
      "Fetching data for PETM...\n",
      "Fetching data for PFE...\n",
      "Fetching data for PFG...\n",
      "Fetching data for PG...\n",
      "Fetching data for PGR...\n",
      "Fetching data for PH...\n",
      "Fetching data for PHM...\n",
      "Fetching data for PKI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PKI: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PLD...\n",
      "Fetching data for PM...\n",
      "Fetching data for PNC...\n",
      "Fetching data for PNR...\n",
      "Fetching data for PNW...\n",
      "Fetching data for PPG...\n",
      "Fetching data for PPL...\n",
      "Fetching data for PRGO...\n",
      "Fetching data for PRU...\n",
      "Fetching data for PSA...\n",
      "Fetching data for PSX...\n",
      "Fetching data for PWR...\n",
      "Fetching data for PXD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PXD: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for QCOM...\n",
      "Fetching data for QEP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$QEP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for R...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RAI: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RAI...\n",
      "Fetching data for RDC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RDC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RF...\n",
      "Fetching data for RHI...\n",
      "Fetching data for RHT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RHT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for RL...\n",
      "Fetching data for ROK...\n",
      "Fetching data for ROP...\n",
      "Fetching data for ROST...\n",
      "Fetching data for RRC...\n",
      "Fetching data for RSG...\n",
      "Fetching data for RTN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RTN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SBUX...\n",
      "Fetching data for SCG...\n",
      "Fetching data for SCHW...\n",
      "Fetching data for SEE...\n",
      "Fetching data for SHW...\n",
      "Fetching data for SIAL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SIAL: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SJM...\n",
      "Fetching data for SLB...\n",
      "Fetching data for SLM...\n",
      "Fetching data for SNA...\n",
      "Fetching data for SNDK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SNDK: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00) (Yahoo error = \"Data doesn't exist for startDate = 1325394000, endDate = 1609477200\")\n",
      "$SNI: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SNI...\n",
      "Fetching data for SO...\n",
      "Fetching data for SPG...\n",
      "Fetching data for SPGI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SPLS: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SPLS...\n",
      "Fetching data for SRCL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SRCL: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SRE...\n",
      "Fetching data for STI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$STI: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00) (Yahoo error = \"Data doesn't exist for startDate = 1325394000, endDate = 1609477200\")\n",
      "$STJ: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for STJ...\n",
      "Fetching data for STT...\n",
      "Fetching data for STX...\n",
      "Fetching data for STZ...\n",
      "Fetching data for SWK...\n",
      "Fetching data for SWN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SWN: possibly delisted; no timezone found\n",
      "$SWY: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SWY...\n",
      "Fetching data for SYK...\n",
      "Fetching data for SYMC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SYMC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SYY...\n",
      "Fetching data for T...\n",
      "Fetching data for TAP...\n",
      "Fetching data for TDC...\n",
      "Fetching data for TE...\n",
      "Fetching data for TEL...\n",
      "Fetching data for TER...\n",
      "Fetching data for TGNA...\n",
      "Fetching data for TGT...\n",
      "Fetching data for THC...\n",
      "Fetching data for TIF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TIF: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TJX...\n",
      "Fetching data for TMK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TMK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TMO...\n",
      "Fetching data for TMUS...\n",
      "Fetching data for TPR...\n",
      "Fetching data for TRIP...\n",
      "Fetching data for TROW...\n",
      "Fetching data for TRV...\n",
      "Fetching data for TSN...\n",
      "Fetching data for TSS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$TSS: possibly delisted; no timezone found\n",
      "$TWC: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TWC...\n",
      "Fetching data for TWX...\n",
      "Fetching data for TXN...\n",
      "Fetching data for TXT...\n",
      "Fetching data for UNH...\n",
      "Fetching data for UNM...\n",
      "Fetching data for UNP...\n",
      "Fetching data for UPS...\n",
      "Fetching data for USB...\n",
      "Fetching data for UTX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$UTX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for V...\n",
      "Fetching data for VAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VAR: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for VFC...\n",
      "Fetching data for VIAB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VIAB: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for VIAV...\n",
      "Fetching data for VLO...\n",
      "Fetching data for VMC...\n",
      "Fetching data for VNO...\n",
      "Fetching data for VRSN...\n",
      "Fetching data for VTR...\n",
      "Fetching data for VZ...\n",
      "Fetching data for WAT...\n",
      "Fetching data for WBA...\n",
      "Fetching data for WDC...\n",
      "Fetching data for WEC...\n",
      "Fetching data for WELL...\n",
      "Fetching data for WFC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WFM: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WFM...\n",
      "Fetching data for WHR...\n",
      "Fetching data for WIN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WIN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WM...\n",
      "Fetching data for WMB...\n",
      "Fetching data for WMT...\n",
      "Fetching data for WPX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WPX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WU...\n",
      "Fetching data for WY...\n",
      "Fetching data for WYNN...\n",
      "Fetching data for X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$X: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for XEL...\n",
      "Fetching data for XLNX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XLNX: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for XOM...\n",
      "Fetching data for XRAY...\n",
      "Fetching data for XRX...\n",
      "Fetching data for XYL...\n",
      "Fetching data for YUM...\n",
      "Fetching data for ZBH...\n",
      "Fetching data for ZION...\n",
      "Fetching data for PVH...\n",
      "Fetching data for REGN...\n",
      "Fetching data for MAC...\n",
      "Fetching data for KSU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KSU: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GM...\n",
      "Fetching data for ZTS...\n",
      "Fetching data for NWSA...\n",
      "Fetching data for NLSN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NLSN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for DAL...\n",
      "Fetching data for AME...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$KORS: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for VRTX...\n",
      "Fetching data for KORS...\n",
      "Fetching data for ALLE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GGP: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for GGP...\n",
      "Fetching data for ADS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ADS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for META...\n",
      "Fetching data for MHK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$GMCR: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSCO...\n",
      "Fetching data for GMCR...\n",
      "Fetching data for ESS...\n",
      "Fetching data for NAVI...\n",
      "Fetching data for UAA...\n",
      "Fetching data for AVGO...\n",
      "Fetching data for XEC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XEC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AMG...\n",
      "Fetching data for MLM...\n",
      "Fetching data for DISCK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DISCK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for UHS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$LVLT: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for URI...\n",
      "Fetching data for LVLT...\n",
      "Fetching data for RCL...\n",
      "Fetching data for ENDP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ENDP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HCA...\n",
      "Fetching data for SWKS...\n",
      "Fetching data for HSIC...\n",
      "Fetching data for AAL...\n",
      "Fetching data for EQIX...\n",
      "Fetching data for HBI...\n",
      "Fetching data for SLG...\n",
      "Fetching data for O...\n",
      "Fetching data for QRVO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BXLT: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BXLT...\n",
      "Fetching data for JBHT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CPGX: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CPGX...\n",
      "Fetching data for WRK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WRK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for KHC...\n",
      "Fetching data for AAP...\n",
      "Fetching data for PYPL...\n",
      "Fetching data for ATVI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ATVI: possibly delisted; no timezone found\n",
      "$CMCSK: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for UAL...\n",
      "Fetching data for CMCSK...\n",
      "Fetching data for NWS...\n",
      "Fetching data for VRSK...\n",
      "Fetching data for HPE...\n",
      "Fetching data for FCPT...\n",
      "Fetching data for SYF...\n",
      "Fetching data for ILMN...\n",
      "Fetching data for CSRA...\n",
      "Fetching data for CHD...\n",
      "Fetching data for CPRI...\n",
      "Fetching data for WLTW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WLTW: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EXR...\n",
      "Fetching data for CFG...\n",
      "Fetching data for FRT...\n",
      "Fetching data for CXO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CXO: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AWK...\n",
      "Fetching data for UDR...\n",
      "Fetching data for CNC...\n",
      "Fetching data for HOLX...\n",
      "Fetching data for FL...\n",
      "Fetching data for UA...\n",
      "Fetching data for ULTA...\n",
      "Fetching data for GPN...\n",
      "Fetching data for AYI...\n",
      "Fetching data for ALK...\n",
      "Fetching data for DLR...\n",
      "Fetching data for LKQ...\n",
      "Fetching data for AJG...\n",
      "Fetching data for TDG...\n",
      "Fetching data for FBHS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FBHS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ALB...\n",
      "Fetching data for LNT...\n",
      "Fetching data for FTV...\n",
      "Fetching data for MTD...\n",
      "Fetching data for CHTR...\n",
      "Fetching data for COO...\n",
      "Fetching data for COTY...\n",
      "Fetching data for EVHC...\n",
      "Fetching data for MAA...\n",
      "Fetching data for IDXX...\n",
      "Fetching data for INCY...\n",
      "Fetching data for CBOE...\n",
      "Fetching data for REG...\n",
      "Fetching data for DISH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DISH: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SNPS...\n",
      "Fetching data for ARE...\n",
      "Fetching data for RJF...\n",
      "Fetching data for IT...\n",
      "Fetching data for INFO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$INFO: possibly delisted; no price data found  (1d 2012-01-01 -> 2021-01-01 00:00:00) (Yahoo error = \"Data doesn't exist for startDate = 1325394000, endDate = 1609477200\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ALGN...\n",
      "Fetching data for ANSS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ANSS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for HLT...\n",
      "Fetching data for RE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$RE: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AOS...\n",
      "Fetching data for DRE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DRE: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for MGM...\n",
      "Fetching data for PKG...\n",
      "Fetching data for RMD...\n",
      "Fetching data for BHF...\n",
      "Fetching data for IQV...\n",
      "Fetching data for DWDP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DWDP: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for SBAC...\n",
      "Fetching data for CDNS...\n",
      "Fetching data for NCLH...\n",
      "Fetching data for HII...\n",
      "Fetching data for IPGP...\n",
      "Fetching data for NKTR...\n",
      "Fetching data for SIVB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SIVB: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TTWO...\n",
      "Fetching data for MSCI...\n",
      "Fetching data for ABMD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ABMD: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for EVRG...\n",
      "Fetching data for BR...\n",
      "Fetching data for HFC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HFC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for FLT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FLT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CPRT...\n",
      "Fetching data for ANET...\n",
      "Fetching data for WCG...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$WCG: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ROL...\n",
      "Fetching data for FTNT...\n",
      "Fetching data for KEYS...\n",
      "Fetching data for LIN...\n",
      "Fetching data for JKHY...\n",
      "Fetching data for FANG...\n",
      "Fetching data for LW...\n",
      "Fetching data for MXIM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$MXIM: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for CE...\n",
      "Fetching data for FRC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$FRC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TFX...\n",
      "Fetching data for ATO...\n",
      "Fetching data for WAB...\n",
      "Fetching data for LHX...\n",
      "Fetching data for CTVA...\n",
      "Fetching data for AMCR...\n",
      "Fetching data for MKTX...\n",
      "Fetching data for GL...\n",
      "Fetching data for IEX...\n",
      "Fetching data for CDW...\n",
      "Fetching data for NVR...\n",
      "Fetching data for LVS...\n",
      "Fetching data for BKR...\n",
      "Fetching data for NLOK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NLOK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for PEAK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PEAK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for NOW...\n",
      "Fetching data for VIAC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$VIAC: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for WRB...\n",
      "Fetching data for ODFL...\n",
      "Fetching data for TFC...\n",
      "Fetching data for J...\n",
      "Fetching data for LYV...\n",
      "Fetching data for STE...\n",
      "Fetching data for ZBRA...\n",
      "Fetching data for PAYC...\n",
      "Fetching data for TT...\n",
      "Fetching data for CARR...\n",
      "Fetching data for OTIS...\n",
      "Fetching data for RTX...\n",
      "Fetching data for HWM...\n",
      "Fetching data for DPZ...\n",
      "Fetching data for DXCM...\n",
      "Fetching data for WST...\n",
      "Fetching data for BIO...\n",
      "Fetching data for TDY...\n",
      "Fetching data for TYL...\n",
      "Fetching data for LUMN...\n",
      "Fetching data for CTLT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$CTLT: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for ETSY...\n",
      "Fetching data for POOL...\n",
      "Fetching data for VNT...\n",
      "Fetching data for VTRS...\n",
      "Fetching data for TSLA...\n"
     ]
    }
   ],
   "source": [
    "start_date = '2012-01-01' # we start from 2012 to have a buffer for moving averages calculation\n",
    "end_date = '2020-12-31' # we end at 2020-12-31, 2019-2020 will be held out for stress testing\n",
    "yfinance_data = []\n",
    "failed_tickers = []\n",
    "successful_tickers = []\n",
    "for ticker in unique_tickers:\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    ticker_data = get_stock_data(ticker, start_date, end_date)\n",
    "    if not ticker_data.empty:\n",
    "        yfinance_data.append(ticker_data)\n",
    "        successful_tickers.append(ticker)\n",
    "    else:\n",
    "        failed_tickers.append(ticker)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a6c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03 00:00:00-05:00</td>\n",
       "      <td>22.776927</td>\n",
       "      <td>23.507771</td>\n",
       "      <td>22.713375</td>\n",
       "      <td>23.183659</td>\n",
       "      <td>4156394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04 00:00:00-05:00</td>\n",
       "      <td>22.973940</td>\n",
       "      <td>23.107398</td>\n",
       "      <td>22.618049</td>\n",
       "      <td>22.999359</td>\n",
       "      <td>4651845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05 00:00:00-05:00</td>\n",
       "      <td>22.802342</td>\n",
       "      <td>23.717486</td>\n",
       "      <td>22.700660</td>\n",
       "      <td>23.514122</td>\n",
       "      <td>6842651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06 00:00:00-05:00</td>\n",
       "      <td>23.571317</td>\n",
       "      <td>23.870010</td>\n",
       "      <td>23.393373</td>\n",
       "      <td>23.768328</td>\n",
       "      <td>4711400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09 00:00:00-05:00</td>\n",
       "      <td>23.908143</td>\n",
       "      <td>24.416557</td>\n",
       "      <td>23.812815</td>\n",
       "      <td>24.391136</td>\n",
       "      <td>4429563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date       Open       High        Low      Close  \\\n",
       "0 2012-01-03 00:00:00-05:00  22.776927  23.507771  22.713375  23.183659   \n",
       "1 2012-01-04 00:00:00-05:00  22.973940  23.107398  22.618049  22.999359   \n",
       "2 2012-01-05 00:00:00-05:00  22.802342  23.717486  22.700660  23.514122   \n",
       "3 2012-01-06 00:00:00-05:00  23.571317  23.870010  23.393373  23.768328   \n",
       "4 2012-01-09 00:00:00-05:00  23.908143  24.416557  23.812815  24.391136   \n",
       "\n",
       "    Volume Dividends  Stock Splits ticker  \n",
       "0  4156394       0.0           0.0      A  \n",
       "1  4651845       0.0           0.0      A  \n",
       "2  6842651       0.0           0.0      A  \n",
       "3  4711400       0.0           0.0      A  \n",
       "4  4429563       0.0           0.0      A  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all individual DataFrames into one big DataFrame\n",
    "yfinance_df = pd.concat(yfinance_data, ignore_index=True)\n",
    "\n",
    "# optional: ensure 'Date' is a proper datetime column\n",
    "yfinance_df[\"Date\"] = pd.to_datetime(yfinance_df[\"Date\"])\n",
    "\n",
    "# preview result\n",
    "yfinance_df.drop(columns=['Capital Gains'], inplace=True)\n",
    "yfinance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0c19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>2020-08-24 00:00:00-04:00</td>\n",
       "      <td>125.186327</td>\n",
       "      <td>125.271449</td>\n",
       "      <td>120.556197</td>\n",
       "      <td>122.423813</td>\n",
       "      <td>345937600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>2020-08-25 00:00:00-04:00</td>\n",
       "      <td>121.295471</td>\n",
       "      <td>121.764805</td>\n",
       "      <td>119.695346</td>\n",
       "      <td>121.419487</td>\n",
       "      <td>211495600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>2020-08-26 00:00:00-04:00</td>\n",
       "      <td>122.737539</td>\n",
       "      <td>123.527873</td>\n",
       "      <td>121.669978</td>\n",
       "      <td>123.070694</td>\n",
       "      <td>163022400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>2020-08-27 00:00:00-04:00</td>\n",
       "      <td>123.673754</td>\n",
       "      <td>124.006909</td>\n",
       "      <td>120.454054</td>\n",
       "      <td>121.599434</td>\n",
       "      <td>155552400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>2020-08-28 00:00:00-04:00</td>\n",
       "      <td>122.574600</td>\n",
       "      <td>122.992869</td>\n",
       "      <td>121.178753</td>\n",
       "      <td>121.402481</td>\n",
       "      <td>187630000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>2020-08-31 00:00:00-04:00</td>\n",
       "      <td>124.099341</td>\n",
       "      <td>127.426034</td>\n",
       "      <td>122.562445</td>\n",
       "      <td>125.519501</td>\n",
       "      <td>225702700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>2020-09-01 00:00:00-04:00</td>\n",
       "      <td>129.138014</td>\n",
       "      <td>131.122367</td>\n",
       "      <td>126.968858</td>\n",
       "      <td>130.519272</td>\n",
       "      <td>151948100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>2020-09-02 00:00:00-04:00</td>\n",
       "      <td>133.836235</td>\n",
       "      <td>134.215594</td>\n",
       "      <td>123.535157</td>\n",
       "      <td>127.815109</td>\n",
       "      <td>200119000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>2020-09-03 00:00:00-04:00</td>\n",
       "      <td>123.447617</td>\n",
       "      <td>125.324955</td>\n",
       "      <td>117.212493</td>\n",
       "      <td>117.582123</td>\n",
       "      <td>257599600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>2020-09-04 00:00:00-04:00</td>\n",
       "      <td>116.794209</td>\n",
       "      <td>120.325172</td>\n",
       "      <td>107.864661</td>\n",
       "      <td>117.659927</td>\n",
       "      <td>332607200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date        Open        High         Low  \\\n",
       "4439 2020-08-24 00:00:00-04:00  125.186327  125.271449  120.556197   \n",
       "4440 2020-08-25 00:00:00-04:00  121.295471  121.764805  119.695346   \n",
       "4441 2020-08-26 00:00:00-04:00  122.737539  123.527873  121.669978   \n",
       "4442 2020-08-27 00:00:00-04:00  123.673754  124.006909  120.454054   \n",
       "4443 2020-08-28 00:00:00-04:00  122.574600  122.992869  121.178753   \n",
       "4444 2020-08-31 00:00:00-04:00  124.099341  127.426034  122.562445   \n",
       "4445 2020-09-01 00:00:00-04:00  129.138014  131.122367  126.968858   \n",
       "4446 2020-09-02 00:00:00-04:00  133.836235  134.215594  123.535157   \n",
       "4447 2020-09-03 00:00:00-04:00  123.447617  125.324955  117.212493   \n",
       "4448 2020-09-04 00:00:00-04:00  116.794209  120.325172  107.864661   \n",
       "\n",
       "           Close     Volume Dividends  Stock Splits ticker  \n",
       "4439  122.423813  345937600       0.0           0.0   AAPL  \n",
       "4440  121.419487  211495600       0.0           0.0   AAPL  \n",
       "4441  123.070694  163022400       0.0           0.0   AAPL  \n",
       "4442  121.599434  155552400       0.0           0.0   AAPL  \n",
       "4443  121.402481  187630000       0.0           0.0   AAPL  \n",
       "4444  125.519501  225702700       0.0           4.0   AAPL  \n",
       "4445  130.519272  151948100       0.0           0.0   AAPL  \n",
       "4446  127.815109  200119000       0.0           0.0   AAPL  \n",
       "4447  117.582123  257599600       0.0           0.0   AAPL  \n",
       "4448  117.659927  332607200       0.0           0.0   AAPL  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for stock split price adjustment, for example apple, check the dates around 2020-08-31 when apple had a 4-for-1 stock split\n",
    "yfinance_df[yfinance_df['Date'].between('2020-08-24', '2020-09-07') & (yfinance_df['ticker'] == 'AAPL')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7929c60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "      <th>is_in_sp500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>22.776927</td>\n",
       "      <td>23.507771</td>\n",
       "      <td>22.713375</td>\n",
       "      <td>23.183659</td>\n",
       "      <td>4156394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>22.973940</td>\n",
       "      <td>23.107398</td>\n",
       "      <td>22.618049</td>\n",
       "      <td>22.999359</td>\n",
       "      <td>4651845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>22.802342</td>\n",
       "      <td>23.717486</td>\n",
       "      <td>22.700660</td>\n",
       "      <td>23.514122</td>\n",
       "      <td>6842651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>23.571317</td>\n",
       "      <td>23.870010</td>\n",
       "      <td>23.393373</td>\n",
       "      <td>23.768328</td>\n",
       "      <td>4711400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>23.908143</td>\n",
       "      <td>24.416557</td>\n",
       "      <td>23.812815</td>\n",
       "      <td>24.391136</td>\n",
       "      <td>4429563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close   Volume Dividends  \\\n",
       "0  2012-01-03  22.776927  23.507771  22.713375  23.183659  4156394       0.0   \n",
       "1  2012-01-04  22.973940  23.107398  22.618049  22.999359  4651845       0.0   \n",
       "2  2012-01-05  22.802342  23.717486  22.700660  23.514122  6842651       0.0   \n",
       "3  2012-01-06  23.571317  23.870010  23.393373  23.768328  4711400       0.0   \n",
       "4  2012-01-09  23.908143  24.416557  23.812815  24.391136  4429563       0.0   \n",
       "\n",
       "   Stock Splits ticker  is_in_sp500  \n",
       "0           0.0      A            0  \n",
       "1           0.0      A            0  \n",
       "2           0.0      A            0  \n",
       "3           0.0      A            0  \n",
       "4           0.0      A            0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure both columns are in the same format\n",
    "yfinance_df[\"Date\"] = pd.to_datetime(yfinance_df[\"Date\"]).dt.date\n",
    "spy_stocklist_filtered_expanded[\"date\"] = pd.to_datetime(spy_stocklist_filtered_expanded[\"date\"]).dt.date\n",
    "\n",
    "# Create a set of (date, ticker) pairs for fast lookup\n",
    "spy_set = set(zip(spy_stocklist_filtered_expanded[\"date\"], spy_stocklist_filtered_expanded[\"ticker\"]))\n",
    "\n",
    "# Add indicator column: 1 if (Date, Ticker) is in SPY list, else 0\n",
    "yfinance_df[\"is_in_sp500\"] = [\n",
    "    1 if (d, t) in spy_set else 0 for d, t in zip(yfinance_df[\"Date\"], yfinance_df[\"ticker\"])\n",
    "]\n",
    "\n",
    "yfinance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1891bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tickers after filtering: 510, tickers filtered out: 129\n"
     ]
    }
   ],
   "source": [
    "# filtering stocks that entered the stock market after 2016-01-01 to ensure we have enough training data per stock\n",
    "\n",
    "first_trade = yfinance_df.groupby(\"ticker\")[\"Date\"].min().reset_index()\n",
    "first_trade[\"Date\"] = pd.to_datetime(first_trade[\"Date\"])\n",
    "first_trade.columns = [\"ticker\", \"first_trade_date\"]\n",
    "\n",
    "# keep only tickers that started before or on 2016-12-31\n",
    "eligible_tickers = first_trade[first_trade[\"first_trade_date\"] <= \"2016-12-31\"][\"ticker\"]\n",
    "\n",
    "yfinance_df_filtered_relavant_stocks = filtered_df = yfinance_df[yfinance_df[\"ticker\"].isin(eligible_tickers)].copy()\n",
    "\n",
    "\n",
    "print(f\"Total tickers after filtering: {eligible_tickers.nunique()}, tickers filtered out: {len(unique_tickers) - eligible_tickers.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68d585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting daily returns, monthly returns and adding to the dataframe\n",
    "# we take 21 trading days as approximately 1 month\n",
    "\n",
    "yfinance_df_filtered_relavant_stocks.sort_values(by=['ticker', 'Date'], inplace=True)\n",
    "yfinance_df_filtered_relavant_stocks['daily_return'] = yfinance_df_filtered_relavant_stocks.groupby('ticker')['Close'].pct_change()\n",
    "yfinance_df_filtered_relavant_stocks['monthly_return'] = yfinance_df_filtered_relavant_stocks.groupby('ticker')['Close'].pct_change(periods=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting monthly standard deviation (volatility) (TODO)\n",
    "yfinance_df_filtered_relavant_stocks[\"monthly_var_3\"] = (\n",
    "    yfinance_df_filtered_relavant_stocks.groupby(\"ticker\")[\"monthly_return\"]\n",
    "      .transform(lambda x: x.rolling(window=3, min_periods=3).var(ddof=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c752e02",
   "metadata": {},
   "source": [
    "### Creating new features\n",
    "#### Moving averages\n",
    "https://www.investopedia.com/ask/answers/122414/what-are-most-common-periods-used-creating-moving-average-ma-lines.asp we will use short:20 days, medium: 50 days, long: 100 days moving averages\n",
    "1) Simple moving average SMA: SMA_20, SMA_50, SMA_100\n",
    "2) Exponential Moving Average EMA https://www.investopedia.com/terms/e/ema.asp#toc-formula-for-exponential-moving-average-ema: EMA_20, EMA_50, EMA_100\n",
    "\n",
    "#### RSI and MACD\n",
    "1) Relative Strength Index 14 days https://www.investopedia.com/terms/r/rsi.asp : RSI\n",
    "2) Moving Average Convergence/Divergence indicator: https://www.investopedia.com/terms/m/macd.asp: MACD_26, MACD_12, MACD_9 \n",
    "\n",
    "#### Stock Splits\n",
    "1) Forward stock split (Stock split > 1): Commonly known as a bullish indicator which provides more liquidity (when fractional shares werent common)\n",
    "2) Reverse stock split (0 < Stock split < 1): Bearish indicator\n",
    "3) Days since stock forward stock split\n",
    "4) Days since reverse stock split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sma(series: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"Simple Moving Average.\"\"\"\n",
    "    return series.rolling(window, min_periods=window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b4eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(series: pd.Series, span: int) -> pd.Series:\n",
    "    \"\"\"Exponential Moving Average.\"\"\"\n",
    "    return series.ewm(span=span, adjust=False, min_periods=span).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8757c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi_wilder(series: pd.Series, period: int = 14) -> pd.Series:\n",
    "    \"\"\"Wilder's RSI (default 14).\"\"\"\n",
    "    delta = series.diff()\n",
    "    gain  = delta.clip(lower=0)\n",
    "    loss  = -delta.clip(upper=0)\n",
    "    avg_gain = gain.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
    "    avg_loss = loss.ewm(alpha=1/period, adjust=False, min_periods=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    return 100 - (100 / (1 + rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9257ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macd(series: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):\n",
    "    \"\"\"\n",
    "    MACD parts: returns DataFrame with MACD_Line, MACD_Signal, MACD_Hist.\n",
    "    \"\"\"\n",
    "    ema_fast = ema(series, fast)\n",
    "    ema_slow = ema(series, slow)\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    macd_signal = macd_line.ewm(span=signal, adjust=False, min_periods=signal).mean()\n",
    "    macd_hist = macd_line - macd_signal\n",
    "    return pd.DataFrame(\n",
    "        {\"MACD_Line\": macd_line, \"MACD_Signal\": macd_signal, \"MACD_Hist\": macd_hist},\n",
    "        index=series.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609f2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "      <th>is_in_sp500</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA_100</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>EMA_100</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD_Line</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>is_forward_split</th>\n",
       "      <th>is_reverse_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>22.776927</td>\n",
       "      <td>23.507771</td>\n",
       "      <td>22.713375</td>\n",
       "      <td>23.183659</td>\n",
       "      <td>4156394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>22.973940</td>\n",
       "      <td>23.107398</td>\n",
       "      <td>22.618049</td>\n",
       "      <td>22.999359</td>\n",
       "      <td>4651845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>22.802342</td>\n",
       "      <td>23.717486</td>\n",
       "      <td>22.700660</td>\n",
       "      <td>23.514122</td>\n",
       "      <td>6842651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>23.571317</td>\n",
       "      <td>23.870010</td>\n",
       "      <td>23.393373</td>\n",
       "      <td>23.768328</td>\n",
       "      <td>4711400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>23.908143</td>\n",
       "      <td>24.416557</td>\n",
       "      <td>23.812815</td>\n",
       "      <td>24.391136</td>\n",
       "      <td>4429563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839121</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>153.424249</td>\n",
       "      <td>155.295040</td>\n",
       "      <td>153.357100</td>\n",
       "      <td>154.191757</td>\n",
       "      <td>417400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.709180</td>\n",
       "      <td>154.477098</td>\n",
       "      <td>154.663482</td>\n",
       "      <td>151.699308</td>\n",
       "      <td>48.711756</td>\n",
       "      <td>-0.298371</td>\n",
       "      <td>-0.514776</td>\n",
       "      <td>0.216405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839122</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>154.882551</td>\n",
       "      <td>156.216091</td>\n",
       "      <td>153.798445</td>\n",
       "      <td>155.793961</td>\n",
       "      <td>1522400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.755876</td>\n",
       "      <td>154.602513</td>\n",
       "      <td>154.707814</td>\n",
       "      <td>151.780390</td>\n",
       "      <td>52.813442</td>\n",
       "      <td>-0.160572</td>\n",
       "      <td>-0.443935</td>\n",
       "      <td>0.283363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839123</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>156.580649</td>\n",
       "      <td>158.393879</td>\n",
       "      <td>155.803537</td>\n",
       "      <td>156.494293</td>\n",
       "      <td>1188400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.774984</td>\n",
       "      <td>154.782683</td>\n",
       "      <td>154.777872</td>\n",
       "      <td>151.873735</td>\n",
       "      <td>54.525369</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>-0.354131</td>\n",
       "      <td>0.359217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839124</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>156.868410</td>\n",
       "      <td>158.106020</td>\n",
       "      <td>156.532636</td>\n",
       "      <td>157.597549</td>\n",
       "      <td>1009000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.828599</td>\n",
       "      <td>155.050765</td>\n",
       "      <td>154.888448</td>\n",
       "      <td>151.987078</td>\n",
       "      <td>57.162019</td>\n",
       "      <td>0.222826</td>\n",
       "      <td>-0.238739</td>\n",
       "      <td>0.461566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839125</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>157.818207</td>\n",
       "      <td>158.950269</td>\n",
       "      <td>156.599788</td>\n",
       "      <td>158.777588</td>\n",
       "      <td>1292600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.901586</td>\n",
       "      <td>155.405701</td>\n",
       "      <td>155.040963</td>\n",
       "      <td>152.121543</td>\n",
       "      <td>59.843900</td>\n",
       "      <td>0.485016</td>\n",
       "      <td>-0.093988</td>\n",
       "      <td>0.579004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1127063 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Open        High         Low       Close   Volume  \\\n",
       "0      2012-01-03   22.776927   23.507771   22.713375   23.183659  4156394   \n",
       "1      2012-01-04   22.973940   23.107398   22.618049   22.999359  4651845   \n",
       "2      2012-01-05   22.802342   23.717486   22.700660   23.514122  6842651   \n",
       "3      2012-01-06   23.571317   23.870010   23.393373   23.768328  4711400   \n",
       "4      2012-01-09   23.908143   24.416557   23.812815   24.391136  4429563   \n",
       "...           ...         ...         ...         ...         ...      ...   \n",
       "839121 2020-12-24  153.424249  155.295040  153.357100  154.191757   417400   \n",
       "839122 2020-12-28  154.882551  156.216091  153.798445  155.793961  1522400   \n",
       "839123 2020-12-29  156.580649  158.393879  155.803537  156.494293  1188400   \n",
       "839124 2020-12-30  156.868410  158.106020  156.532636  157.597549  1009000   \n",
       "839125 2020-12-31  157.818207  158.950269  156.599788  158.777588  1292600   \n",
       "\n",
       "       Dividends  Stock Splits ticker  is_in_sp500  ...     SMA_100  \\\n",
       "0            0.0           0.0      A            0  ...         NaN   \n",
       "1            0.0           0.0      A            0  ...         NaN   \n",
       "2            0.0           0.0      A            0  ...         NaN   \n",
       "3            0.0           0.0      A            0  ...         NaN   \n",
       "4            0.0           0.0      A            0  ...         NaN   \n",
       "...          ...           ...    ...          ...  ...         ...   \n",
       "839121       0.0           0.0    ZTS            0  ...  154.709180   \n",
       "839122       0.0           0.0    ZTS            0  ...  154.755876   \n",
       "839123       0.0           0.0    ZTS            0  ...  154.774984   \n",
       "839124       0.0           0.0    ZTS            0  ...  154.828599   \n",
       "839125       0.0           0.0    ZTS            0  ...  154.901586   \n",
       "\n",
       "            EMA_20      EMA_50     EMA_100        RSI  MACD_Line  MACD_Signal  \\\n",
       "0              NaN         NaN         NaN        NaN        NaN          NaN   \n",
       "1              NaN         NaN         NaN        NaN        NaN          NaN   \n",
       "2              NaN         NaN         NaN        NaN        NaN          NaN   \n",
       "3              NaN         NaN         NaN        NaN        NaN          NaN   \n",
       "4              NaN         NaN         NaN        NaN        NaN          NaN   \n",
       "...            ...         ...         ...        ...        ...          ...   \n",
       "839121  154.477098  154.663482  151.699308  48.711756  -0.298371    -0.514776   \n",
       "839122  154.602513  154.707814  151.780390  52.813442  -0.160572    -0.443935   \n",
       "839123  154.782683  154.777872  151.873735  54.525369   0.005086    -0.354131   \n",
       "839124  155.050765  154.888448  151.987078  57.162019   0.222826    -0.238739   \n",
       "839125  155.405701  155.040963  152.121543  59.843900   0.485016    -0.093988   \n",
       "\n",
       "        MACD_Hist  is_forward_split  is_reverse_split  \n",
       "0             NaN                 0                 0  \n",
       "1             NaN                 0                 0  \n",
       "2             NaN                 0                 0  \n",
       "3             NaN                 0                 0  \n",
       "4             NaN                 0                 0  \n",
       "...           ...               ...               ...  \n",
       "839121   0.216405                 0                 0  \n",
       "839122   0.283363                 0                 0  \n",
       "839123   0.359217                 0                 0  \n",
       "839124   0.461566                 0                 0  \n",
       "839125   0.579004                 0                 0  \n",
       "\n",
       "[1127063 rows x 25 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = yfinance_df_filtered_relavant_stocks.copy()\n",
    "\n",
    "# Ensure types/order; compute per-ticker\n",
    "temp_df['Date'] = pd.to_datetime(temp_df['Date'])\n",
    "temp_df = temp_df.drop_duplicates(subset=['ticker','Date']).sort_values(['ticker','Date'])\n",
    "\n",
    "\n",
    "g = temp_df.groupby('ticker', group_keys=False)\n",
    "\n",
    "# SMA 20/50/100\n",
    "for w in [20, 50, 100]:\n",
    "    temp_df[f'SMA_{w}'] = g['Close'].transform(lambda s, w=w: sma(s, w))\n",
    "\n",
    "# EMA 20/50/100\n",
    "for w in [20, 50, 100]:\n",
    "    temp_df[f'EMA_{w}'] = g['Close'].transform(lambda s, w=w: ema(s, w))\n",
    "\n",
    "# RSI 14\n",
    "temp_df['RSI'] = g['Close'].transform(rsi_wilder)\n",
    "\n",
    "# MACD (12,26,9)\n",
    "macd_df = g['Close'].apply(macd)\n",
    "temp_df = temp_df.join(macd_df)\n",
    "\n",
    "# Stock Splits\n",
    "temp_df[\"is_forward_split\"] = (yfinance_df[\"Stock Splits\"] > 1).astype(int)\n",
    "temp_df[\"is_reverse_split\"] = ((yfinance_df[\"Stock Splits\"] > 0) & \n",
    "                                   (yfinance_df[\"Stock Splits\"] < 1)).astype(int) \n",
    "\n",
    "SP500_all_stock_data = temp_df\n",
    "\n",
    "\n",
    "SP500_all_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb4b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "      <th>is_in_sp500</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA_100</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>EMA_100</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD_Line</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>is_forward_split</th>\n",
       "      <th>is_reverse_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>22.776927</td>\n",
       "      <td>23.507771</td>\n",
       "      <td>22.713375</td>\n",
       "      <td>23.183659</td>\n",
       "      <td>4156394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>22.973940</td>\n",
       "      <td>23.107398</td>\n",
       "      <td>22.618049</td>\n",
       "      <td>22.999359</td>\n",
       "      <td>4651845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>22.802342</td>\n",
       "      <td>23.717486</td>\n",
       "      <td>22.700660</td>\n",
       "      <td>23.514122</td>\n",
       "      <td>6842651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>23.571317</td>\n",
       "      <td>23.870010</td>\n",
       "      <td>23.393373</td>\n",
       "      <td>23.768328</td>\n",
       "      <td>4711400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09</td>\n",
       "      <td>23.908143</td>\n",
       "      <td>24.416557</td>\n",
       "      <td>23.812815</td>\n",
       "      <td>24.391136</td>\n",
       "      <td>4429563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Open       High        Low      Close   Volume Dividends  \\\n",
       "0 2012-01-03  22.776927  23.507771  22.713375  23.183659  4156394       0.0   \n",
       "1 2012-01-04  22.973940  23.107398  22.618049  22.999359  4651845       0.0   \n",
       "2 2012-01-05  22.802342  23.717486  22.700660  23.514122  6842651       0.0   \n",
       "3 2012-01-06  23.571317  23.870010  23.393373  23.768328  4711400       0.0   \n",
       "4 2012-01-09  23.908143  24.416557  23.812815  24.391136  4429563       0.0   \n",
       "\n",
       "   Stock Splits ticker  is_in_sp500  ...  SMA_100  EMA_20  EMA_50  EMA_100  \\\n",
       "0           0.0      A            0  ...      0.0     0.0     0.0      0.0   \n",
       "1           0.0      A            0  ...      0.0     0.0     0.0      0.0   \n",
       "2           0.0      A            0  ...      0.0     0.0     0.0      0.0   \n",
       "3           0.0      A            0  ...      0.0     0.0     0.0      0.0   \n",
       "4           0.0      A            0  ...      0.0     0.0     0.0      0.0   \n",
       "\n",
       "   RSI  MACD_Line  MACD_Signal  MACD_Hist  is_forward_split  is_reverse_split  \n",
       "0  0.0        0.0          0.0        0.0                 0                 0  \n",
       "1  0.0        0.0          0.0        0.0                 0                 0  \n",
       "2  0.0        0.0          0.0        0.0                 0                 0  \n",
       "3  0.0        0.0          0.0        0.0                 0                 0  \n",
       "4  0.0        0.0          0.0        0.0                 0                 0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we dont want to backward fill the data as it may introduce lookahead bias, \n",
    "# nor do we want to delete the entries, so for stocks that newly entered the SP500 with insufficient data we fill with 0\n",
    "SP500_all_stock_data.fillna(0, inplace=True)\n",
    "SP500_all_stock_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87ec59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>ticker</th>\n",
       "      <th>is_in_sp500</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA_100</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>EMA_100</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD_Line</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>is_forward_split</th>\n",
       "      <th>is_reverse_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>27.067743</td>\n",
       "      <td>27.067743</td>\n",
       "      <td>26.413034</td>\n",
       "      <td>26.881601</td>\n",
       "      <td>8790205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.462086</td>\n",
       "      <td>25.703240</td>\n",
       "      <td>24.966327</td>\n",
       "      <td>24.735124</td>\n",
       "      <td>64.959710</td>\n",
       "      <td>0.571168</td>\n",
       "      <td>0.559054</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>26.920111</td>\n",
       "      <td>27.048486</td>\n",
       "      <td>26.689037</td>\n",
       "      <td>26.977880</td>\n",
       "      <td>5751791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.472192</td>\n",
       "      <td>25.824635</td>\n",
       "      <td>25.045212</td>\n",
       "      <td>24.779535</td>\n",
       "      <td>65.650113</td>\n",
       "      <td>0.602698</td>\n",
       "      <td>0.567783</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>27.048488</td>\n",
       "      <td>27.568405</td>\n",
       "      <td>26.868764</td>\n",
       "      <td>27.510635</td>\n",
       "      <td>6432897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.486733</td>\n",
       "      <td>25.985206</td>\n",
       "      <td>25.141895</td>\n",
       "      <td>24.833616</td>\n",
       "      <td>69.259439</td>\n",
       "      <td>0.663032</td>\n",
       "      <td>0.586833</td>\n",
       "      <td>0.076199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>27.343750</td>\n",
       "      <td>27.472125</td>\n",
       "      <td>27.202538</td>\n",
       "      <td>27.311657</td>\n",
       "      <td>3589505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.501007</td>\n",
       "      <td>26.111535</td>\n",
       "      <td>25.226984</td>\n",
       "      <td>24.882686</td>\n",
       "      <td>66.450996</td>\n",
       "      <td>0.686873</td>\n",
       "      <td>0.606841</td>\n",
       "      <td>0.080032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>27.260301</td>\n",
       "      <td>27.459282</td>\n",
       "      <td>27.022808</td>\n",
       "      <td>27.093414</td>\n",
       "      <td>3896925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.514058</td>\n",
       "      <td>26.205047</td>\n",
       "      <td>25.300177</td>\n",
       "      <td>24.926463</td>\n",
       "      <td>63.413694</td>\n",
       "      <td>0.680315</td>\n",
       "      <td>0.621536</td>\n",
       "      <td>0.058779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839121</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>153.424249</td>\n",
       "      <td>155.295040</td>\n",
       "      <td>153.357100</td>\n",
       "      <td>154.191757</td>\n",
       "      <td>417400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.709180</td>\n",
       "      <td>154.477098</td>\n",
       "      <td>154.663482</td>\n",
       "      <td>151.699308</td>\n",
       "      <td>48.711756</td>\n",
       "      <td>-0.298371</td>\n",
       "      <td>-0.514776</td>\n",
       "      <td>0.216405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839122</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>154.882551</td>\n",
       "      <td>156.216091</td>\n",
       "      <td>153.798445</td>\n",
       "      <td>155.793961</td>\n",
       "      <td>1522400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.755876</td>\n",
       "      <td>154.602513</td>\n",
       "      <td>154.707814</td>\n",
       "      <td>151.780390</td>\n",
       "      <td>52.813442</td>\n",
       "      <td>-0.160572</td>\n",
       "      <td>-0.443935</td>\n",
       "      <td>0.283363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839123</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>156.580649</td>\n",
       "      <td>158.393879</td>\n",
       "      <td>155.803537</td>\n",
       "      <td>156.494293</td>\n",
       "      <td>1188400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.774984</td>\n",
       "      <td>154.782683</td>\n",
       "      <td>154.777872</td>\n",
       "      <td>151.873735</td>\n",
       "      <td>54.525369</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>-0.354131</td>\n",
       "      <td>0.359217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839124</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>156.868410</td>\n",
       "      <td>158.106020</td>\n",
       "      <td>156.532636</td>\n",
       "      <td>157.597549</td>\n",
       "      <td>1009000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.828599</td>\n",
       "      <td>155.050765</td>\n",
       "      <td>154.888448</td>\n",
       "      <td>151.987078</td>\n",
       "      <td>57.162019</td>\n",
       "      <td>0.222826</td>\n",
       "      <td>-0.238739</td>\n",
       "      <td>0.461566</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839125</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>157.818207</td>\n",
       "      <td>158.950269</td>\n",
       "      <td>156.599788</td>\n",
       "      <td>158.777588</td>\n",
       "      <td>1292600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>154.901586</td>\n",
       "      <td>155.405701</td>\n",
       "      <td>155.040963</td>\n",
       "      <td>152.121543</td>\n",
       "      <td>59.843900</td>\n",
       "      <td>0.485016</td>\n",
       "      <td>-0.093988</td>\n",
       "      <td>0.579004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1007655 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Open        High         Low       Close   Volume  \\\n",
       "250    2013-01-02   27.067743   27.067743   26.413034   26.881601  8790205   \n",
       "251    2013-01-03   26.920111   27.048486   26.689037   26.977880  5751791   \n",
       "252    2013-01-04   27.048488   27.568405   26.868764   27.510635  6432897   \n",
       "253    2013-01-07   27.343750   27.472125   27.202538   27.311657  3589505   \n",
       "254    2013-01-08   27.260301   27.459282   27.022808   27.093414  3896925   \n",
       "...           ...         ...         ...         ...         ...      ...   \n",
       "839121 2020-12-24  153.424249  155.295040  153.357100  154.191757   417400   \n",
       "839122 2020-12-28  154.882551  156.216091  153.798445  155.793961  1522400   \n",
       "839123 2020-12-29  156.580649  158.393879  155.803537  156.494293  1188400   \n",
       "839124 2020-12-30  156.868410  158.106020  156.532636  157.597549  1009000   \n",
       "839125 2020-12-31  157.818207  158.950269  156.599788  158.777588  1292600   \n",
       "\n",
       "       Dividends  Stock Splits ticker  is_in_sp500  ...     SMA_100  \\\n",
       "250          0.0           0.0      A            1  ...   24.462086   \n",
       "251          0.0           0.0      A            1  ...   24.472192   \n",
       "252          0.0           0.0      A            0  ...   24.486733   \n",
       "253          0.0           0.0      A            0  ...   24.501007   \n",
       "254          0.0           0.0      A            1  ...   24.514058   \n",
       "...          ...           ...    ...          ...  ...         ...   \n",
       "839121       0.0           0.0    ZTS            0  ...  154.709180   \n",
       "839122       0.0           0.0    ZTS            0  ...  154.755876   \n",
       "839123       0.0           0.0    ZTS            0  ...  154.774984   \n",
       "839124       0.0           0.0    ZTS            0  ...  154.828599   \n",
       "839125       0.0           0.0    ZTS            0  ...  154.901586   \n",
       "\n",
       "            EMA_20      EMA_50     EMA_100        RSI  MACD_Line  MACD_Signal  \\\n",
       "250      25.703240   24.966327   24.735124  64.959710   0.571168     0.559054   \n",
       "251      25.824635   25.045212   24.779535  65.650113   0.602698     0.567783   \n",
       "252      25.985206   25.141895   24.833616  69.259439   0.663032     0.586833   \n",
       "253      26.111535   25.226984   24.882686  66.450996   0.686873     0.606841   \n",
       "254      26.205047   25.300177   24.926463  63.413694   0.680315     0.621536   \n",
       "...            ...         ...         ...        ...        ...          ...   \n",
       "839121  154.477098  154.663482  151.699308  48.711756  -0.298371    -0.514776   \n",
       "839122  154.602513  154.707814  151.780390  52.813442  -0.160572    -0.443935   \n",
       "839123  154.782683  154.777872  151.873735  54.525369   0.005086    -0.354131   \n",
       "839124  155.050765  154.888448  151.987078  57.162019   0.222826    -0.238739   \n",
       "839125  155.405701  155.040963  152.121543  59.843900   0.485016    -0.093988   \n",
       "\n",
       "        MACD_Hist  is_forward_split  is_reverse_split  \n",
       "250      0.012114                 0                 0  \n",
       "251      0.034915                 0                 0  \n",
       "252      0.076199                 0                 0  \n",
       "253      0.080032                 0                 0  \n",
       "254      0.058779                 0                 0  \n",
       "...           ...               ...               ...  \n",
       "839121   0.216405                 0                 0  \n",
       "839122   0.283363                 0                 0  \n",
       "839123   0.359217                 0                 0  \n",
       "839124   0.461566                 0                 0  \n",
       "839125   0.579004                 0                 0  \n",
       "\n",
       "[1007655 rows x 25 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter for stocks from 2013-01-01 onwards \n",
    "SP500_all_stock_data_final = SP500_all_stock_data[SP500_all_stock_data['Date'] >= pd.to_datetime('2013-01-01')]\n",
    "SP500_all_stock_data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c289d",
   "metadata": {},
   "source": [
    "#### Stationarity checks\n",
    "we will use ADF test for stationarity checks and eliminate serial correlation through transformations if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6066be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adf_all_columns(df):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    results = []\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        series = df[col].dropna()\n",
    "        try:\n",
    "            p_val = adfuller(series, autolag=\"AIC\")[1]\n",
    "            verdict = \"stationary\" if p_val < 0.05 else \"non_stationary\"\n",
    "        except Exception as e:\n",
    "            p_val = np.nan\n",
    "            verdict = f\"error: {e}\"\n",
    "\n",
    "        results.append({\n",
    "            \"column\": col,\n",
    "            \"ADF_p\": p_val,\n",
    "            \"Verdict\": verdict\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1edc86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_adf_all_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m adf_results = \u001b[43mcheck_adf_all_columns\u001b[49m(SP500_all_stock_data_final)\n\u001b[32m      2\u001b[39m display(adf_results)\n",
      "\u001b[31mNameError\u001b[39m: name 'check_adf_all_columns' is not defined"
     ]
    }
   ],
   "source": [
    "adf_results = check_adf_all_columns(SP500_all_stock_data_final)\n",
    "display(adf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846e0bc",
   "metadata": {},
   "source": [
    "#### Covid hold out set \n",
    "https://en.wikipedia.org/wiki/2020_stock_market_crash#:~:text=Though%20the%20crash%20began%20on,13%25%20in%20most%20global%20markets.\n",
    "\n",
    "Covid stock crash happened on: 20 Feb\n",
    "we will use 2013-01-01 to 2020-02-19 data as our training test set and 2020-02-19 to 2020-12-12 as our holdout set\n",
    "\n",
    "Purging will happen later using 100 days during time-series CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9764604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data appropriately into training, test and covid stress test data \n",
    "# Covid data https://en.wikipedia.org/wiki/2020_stock_market_crash#:~:text=Though%20the%20crash%20began%20on,13%25%20in%20most%20global%20markets.\n",
    "COVID_start_date = '2020-02-20'\n",
    "training_data =  SP500_all_stock_data_final[SP500_all_stock_data_final['Date'] < pd.to_datetime(COVID_start_date)]\n",
    "covid_stress_test_data = SP500_all_stock_data_final[SP500_all_stock_data_final['Date'] >= pd.to_datetime(COVID_start_date)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
